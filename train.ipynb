{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKXbvPtmIAzW"
   },
   "source": [
    "# Aleket Faster R-CNN training notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T09:04:42.063720Z",
     "start_time": "2024-10-23T09:04:22.868274Z"
    },
    "executionInfo": {
     "elapsed": 7480,
     "status": "ok",
     "timestamp": 1726688885304,
     "user": {
      "displayName": "maximus JV",
      "userId": "01037924598235015782"
     },
     "user_tz": -180
    },
    "id": "QYh3of1UgFZs"
   },
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "\n",
    "# Standard Library\n",
    "import os\n",
    "\n",
    "# Third-Party Libraries\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "from torchvision.models.detection import (\n",
    "    FasterRCNN,\n",
    "    fasterrcnn_resnet50_fpn,\n",
    "    fasterrcnn_resnet50_fpn_v2,\n",
    "    fasterrcnn_mobilenet_v3_large_fpn,\n",
    ")\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# Utils\n",
    "from finetuning.aleket_dataset import AleketDataset, download_dataset\n",
    "from finetuning.checkpoints import load_checkpoint, RunParams\n",
    "from finetuning.metrics import Evaluator\n",
    "from finetuning.training_and_evaluation import train\n",
    "from utils.analyze import count_analyze\n",
    "from infer import infer\n",
    "from utils.visualize import visualize_bboxes, draw_heat_map\n",
    "from utils.predictor import Predictor\n",
    "from utils.consts import NUM_TO_CLASSES, VALIDATION_METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T09:04:42.389081Z",
     "start_time": "2024-10-23T09:04:42.120733Z"
    }
   },
   "outputs": [],
   "source": [
    "def visualize_samples(dataset, images_to_visualize=4):\n",
    "    \"\"\"\n",
    "    Visualizes samples from the dataset with bounding boxes and labels.\n",
    "\n",
    "    Args:\n",
    "        dataset (AleketDataset): The dataset to visualize samples from.\n",
    "        images_to_visualize (int, optional): The number of images to visualize. Defaults to 4.\n",
    "    \"\"\"\n",
    "    visualized_images = []\n",
    "\n",
    "    for id, annot in enumerate(dataset.get_annots(None)):\n",
    "        if len(annot[\"boxes\"]) > 0:\n",
    "            img, target = dataset[id]\n",
    "            img = v2.functional.to_pil_image(img)\n",
    "\n",
    "            bboxes = target[\"boxes\"].cpu().tolist()\n",
    "            labels = [NUM_TO_CLASSES[label.item()] for label in target[\"labels\"]]\n",
    "\n",
    "            img_with_boxes = visualize_bboxes(img, bboxes, labels)\n",
    "            visualized_images.append(img_with_boxes)\n",
    "            if len(visualized_images) == images_to_visualize:\n",
    "                break\n",
    "\n",
    "    fig = plt.figure(figsize=(60, 20))\n",
    "    columns = 4\n",
    "    rows = 1\n",
    "    for i in range(1, columns * rows + 1):\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        plt.imshow(visualized_images[i - 1])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_model(device, trainable_backbone_layers=3):\n",
    "    \"\"\"\n",
    "    Loads a pretrained Faster R-CNN ResNet-50 FPN model and modifies the classification head\n",
    "    to accommodate the specified number of classes in dataset (3 - including background).\n",
    "\n",
    "    Args:\n",
    "        device (torch.device): The device to move the model to (e.g., 'cuda' or 'cpu').\n",
    "        trainable_backbone_layers (int, optional): Number of trainable backbone layers. Defaults to 3.\n",
    "\n",
    "    Returns:\n",
    "        FasterRCNN: The Faster R-CNN model with the modified classification head.\n",
    "    \"\"\"\n",
    "    model = fasterrcnn_resnet50_fpn_v2(\n",
    "        weights=\"DEFAULT\", trainable_backbone_layers=trainable_backbone_layers\n",
    "    )\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, 3)\n",
    "\n",
    "    return model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device Selection\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Random Seed for Dataset split\n",
    "SEED = 1\n",
    "np_generator = np.random.default_rng(SEED)\n",
    "\n",
    "# Dataset split\n",
    "DATASET_FRACTION = 1\n",
    "VALIDATION_FRACTION = 0.2\n",
    "patched_dataset = AleketDataset(download_dataset(\"dataset_patched\", \"\"))\n",
    "full_dataset = AleketDataset(download_dataset(\"dataset_full_images\", \"\"))\n",
    "train_set, val_set = patched_dataset.split_dataset(\n",
    "    DATASET_FRACTION, VALIDATION_FRACTION, np_generator\n",
    ")\n",
    "\n",
    "# Model\n",
    "model = get_model(device, trainable_backbone_layers=5)\n",
    "\n",
    "print(f\"Using model: {model._get_name()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_NAME = \"finalrun_v2_tb=5\"\n",
    "\n",
    "TRAIN_COMPLETE = False\n",
    "params = RunParams(\n",
    "    run_name=RUN_NAME,\n",
    "    batch_size=8,\n",
    "    dataloader_workers=8, \n",
    "    total_epochs=150,\n",
    "    augmentation={\n",
    "        \"horizontal_flip\": {\n",
    "            \"p\": 0.5\n",
    "        },\n",
    "        \"vertical_flip\": {\n",
    "            \"p\": 0.5\n",
    "        },\n",
    "        \"scale_jitter\": {\n",
    "            \"target_size\": (1024, 1024),\n",
    "            \"scale_range\": (0.8, 1.2)\n",
    "        },\n",
    "        \"perspective\": {\n",
    "            \"distortion_scale\": 0.2,\n",
    "            \"p\": 0.5\n",
    "        },\n",
    "        \"rotation\": {\n",
    "            \"degrees\": 30,\n",
    "            \"expand\": True\n",
    "        },\n",
    "        \"color_jitter\": {\n",
    "            \"brightness\": 0.1,\n",
    "            \"contrast\": 0.1,\n",
    "            \"saturation\": 0.05\n",
    "        }\n",
    "    },\n",
    "    optimizer={\n",
    "        \"lr\": 0.01,\n",
    "        \"weight_decay\": 0.00009\n",
    "    },\n",
    "    lr_scheduler={\n",
    "        \"factor\": 0.1,\n",
    "        \"patience\": 10,\n",
    "        \"min_lr\": 0.0001\n",
    "    },\n",
    "    validation_set=val_set,\n",
    "    train_set=train_set\n",
    "    )\n",
    "\n",
    "\n",
    "print(f\"Train parameters for '{RUN_NAME}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_params = params.parse(model, patched_dataset)\n",
    "train_dataloader = parsed_params[\"train_loader\"]\n",
    "val_dataloader = parsed_params[\"val_loader\"]\n",
    "augmentation = parsed_params[\"augmentation\"]\n",
    "\n",
    "count_analyze(full_dataset.get_annots(), save_folder=\"full_dataset_statistics\")\n",
    "count_analyze(patched_dataset.get_annots(train_dataloader.dataset.indices), save_folder=\"patched_dataset__train_statistics\")\n",
    "count_analyze(patched_dataset.get_annots(val_dataloader.dataset.indices), save_folder=\"patched_dataset_val_statistics\")\n",
    "\n",
    "patched_dataset.augmentation = augmentation\n",
    "visualize_samples(patched_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T09:16:28.489606Z",
     "start_time": "2024-10-23T09:04:42.842532Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G9UdbXiJIAzZ",
    "outputId": "4eaac050-8192-4ffe-e5ae-ee59701ce7b2"
   },
   "outputs": [],
   "source": [
    "#START TRAINING\n",
    "train(model, patched_dataset, params, device, checkpoints=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONTINUE TRAINING FROM CHECKPOINT\n",
    "params = RunParams()\n",
    "params.load(os.path.join(\"results\", RUN_NAME, \"params.json\"))  # override parameters\n",
    "FINISHED = False\n",
    "while not FINISHED:  # might accure some unexcpected errors with bboxes in pytorch code\n",
    "    try:\n",
    "        train(\n",
    "            model,\n",
    "            patched_dataset,\n",
    "            params,\n",
    "            device,\n",
    "            checkpoints=True,\n",
    "            resume=True,\n",
    "            verbose=True,\n",
    "        )\n",
    "        FINISHED = True\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "\n",
    "clear_output(wait=False)\n",
    "print(\"TRAIN COMPLETE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTING\n",
    "RUN_NAME_TO_TEST = RUN_NAME\n",
    "\n",
    "run_dir = os.path.join(\"results\", RUN_NAME_TO_TEST)\n",
    "params_path = os.path.join(run_dir, \"params.json\")\n",
    "checkpoint_path = os.path.join(run_dir,\"checkpoints\", \"best.pth\")\n",
    "\n",
    "params = RunParams()\n",
    "params.load(params_path)\n",
    "\n",
    "val_indices = full_dataset.to_indices(params.validation_set.keys())\n",
    "val_subset = Subset(full_dataset, val_indices)\n",
    "\n",
    "model = load_checkpoint(get_model(device), checkpoint_path)[0]\n",
    "\n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "with open(\"val_image_list.txt\", \"w\") as f:\n",
    "  for name in params.validation_set.keys():\n",
    "    f.write(f\"{os.path.join(full_dataset.img_dir,name)}.jpeg\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = Predictor(\n",
    "    model,\n",
    "    device,\n",
    "    detections_per_patch=150,\n",
    "    detections_per_image=300,\n",
    "    images_per_batch=4,\n",
    "    image_size_factor=1,\n",
    "    patches_per_batch=4,\n",
    ")\n",
    "\n",
    "iou_thrs = np.round(np.flip(np.arange(0.1, 0.5 + 1e-3, 0.1)), 2)\n",
    "score_thrs = np.round(np.arange(0.1, 0.8 + 1e-4, 0.05), 2)\n",
    "\n",
    "np.savetxt(os.path.join(run_dir, \"nms_thrs.csv\"), iou_thrs, delimiter=\",\", fmt=\"%.2f\")\n",
    "np.savetxt(\n",
    "    os.path.join(run_dir, \"score_thrs.csv\"), score_thrs, delimiter=\",\", fmt=\"%.2f\"\n",
    ")\n",
    "\n",
    "N = len(iou_thrs)\n",
    "S = len(score_thrs)\n",
    "\n",
    "eval = Evaluator(full_dataset.get_annots(val_indices))\n",
    "\n",
    "results_ap = np.full((N, S), -1.0)\n",
    "results_aad = np.full((N, S), -1.0)\n",
    "results_acd = np.full((N, S), -1.0)\n",
    "\n",
    "\n",
    "for i, n in enumerate(iou_thrs):\n",
    "    for j, s in tqdm(enumerate(score_thrs), total=S):\n",
    "        try:\n",
    "            preds = predictor.get_predictions(val_subset, n, s)\n",
    "            stats = eval.eval(preds)\n",
    "            results_ap[i, j] = stats[VALIDATION_METRICS[0]]\n",
    "            results_acd[i, j] = stats[VALIDATION_METRICS[-2]]\n",
    "            results_aad[i, j] = stats[VALIDATION_METRICS[-1]]\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\n",
    "    os.path.join(run_dir, \"ap_analysis.csv\"), results_ap, delimiter=\",\", fmt=\"%.4f\"\n",
    ")\n",
    "np.savetxt(\n",
    "    os.path.join(run_dir, \"aad_analysis.csv\"), results_aad, delimiter=\",\", fmt=\"%.4f\"\n",
    ")\n",
    "np.savetxt(\n",
    "    os.path.join(run_dir, \"acd_analysis.csv\"), results_acd, delimiter=\",\", fmt=\"%.4f\"\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(60, 10))\n",
    "\n",
    "draw_heat_map(\"AP\", \"score_thresh\", \"iou_thresh\", results_ap, axes[0], score_thrs, iou_thrs)\n",
    "draw_heat_map(\"AAD\", \"score_thresh\", \"iou_thresh\", results_aad, axes[1], score_thrs, iou_thrs)\n",
    "draw_heat_map(\"ACD\", \"score_thresh\", \"iou_thresh\", results_acd, axes[2], score_thrs, iou_thrs)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = Predictor(\n",
    "    model,\n",
    "    device,\n",
    "    detections_per_patch=150,\n",
    "    detections_per_image=300,\n",
    "    image_size_factor=.5,\n",
    "    images_per_batch=1,\n",
    "    patches_per_batch=4,\n",
    ")\n",
    "\n",
    "image_list = [\n",
    "    os.path.join(f\"{full_dataset.img_dir}\", f\"{name}.jpeg\")\n",
    "    for name in params.validation_set.keys()\n",
    "]\n",
    "\n",
    "infer_dir = os.path.join(run_dir, \"infer2\")\n",
    "os.makedirs(infer_dir, exist_ok=True)\n",
    "\n",
    "infer(\n",
    "    predictor,\n",
    "    images=image_list,\n",
    "    classes=NUM_TO_CLASSES,\n",
    "    output_dir=infer_dir,\n",
    "    iou_thresh=0.2,\n",
    "    score_thresh=0.5,\n",
    "    num_of_annotations_to_save=10,\n",
    "    save_annotated_images=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "https://github.com/maximusjv/AleketML/blob/main/aleket.ipynb",
     "timestamp": 1726685419266
    }
   ]
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
