{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKXbvPtmIAzW"
   },
   "source": [
    "# Aleket Faster R-CNN training notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pillow\n",
    "%pip install numpy<2.0\n",
    "%pip install torch torchvision --index-url https://download.pytorch.org/whl/cu124\n",
    "%pip install matplotlib\n",
    "%pip install gdown\n",
    "%pip install tqdm\n",
    "\n",
    "from IPython.display import clear_output\n",
    "clear_output(wait=False)\n",
    "\n",
    "print(\"ALL DEPENDENCIES INSTALLED\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T09:04:42.063720Z",
     "start_time": "2024-10-23T09:04:22.868274Z"
    },
    "executionInfo": {
     "elapsed": 7480,
     "status": "ok",
     "timestamp": 1726688885304,
     "user": {
      "displayName": "maximus JV",
      "userId": "01037924598235015782"
     },
     "user_tz": -180
    },
    "id": "QYh3of1UgFZs"
   },
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "\n",
    "# Standard Library\n",
    "import os\n",
    "\n",
    "# Third-Party Libraries\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.axes import Axes\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "\n",
    "# Utils\n",
    "from aleket_dataset import AleketDataset, download_dataset, split_dataset\n",
    "from utils import get_model, load_checkpoint\n",
    "from training_and_evaluation import train\n",
    "from dataset_statisics import visualize_samples, count_analyze\n",
    "from run_params import RunParams, parse_params\n",
    "from predictor import Predictor\n",
    "from metrics import Evaluator, VALIDATION_METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T09:04:42.389081Z",
     "start_time": "2024-10-23T09:04:42.120733Z"
    }
   },
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def augment_example(ds):\n",
    "    examples = visualize_samples(ds, image_ids_to_visualize=list(range(4)))\n",
    "    fig=plt.figure(figsize=(40, 10))\n",
    "    columns = 4\n",
    "    rows = 1\n",
    "    for i in range(1, columns*rows +1):\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        plt.imshow(examples[i-1])\n",
    "    plt.show()\n",
    "\n",
    "def draw_heat_map(name: str, values: np.ndarray, ax: Axes, x_ticks: np.ndarray, y_ticks: np.ndarray):\n",
    "\n",
    "    masked_results = np.ma.masked_where(values == -1, values)\n",
    "    ax.imshow(masked_results, cmap='viridis', vmin=0, interpolation='nearest')\n",
    "\n",
    "    X = len(x_ticks)\n",
    "    Y = len(y_ticks)\n",
    "\n",
    "    ax.set_title(name)\n",
    "    ax.set_xlabel('Score Threshold')\n",
    "    ax.set_ylabel('NMS Threshold')\n",
    "    ax.set_xticks(np.arange(X))\n",
    "    ax.set_yticks(np.arange(Y))\n",
    "    ax.set_xticklabels(x_ticks)\n",
    "    ax.set_yticklabels(y_ticks)\n",
    "    max_val = values.max()\n",
    "    \n",
    "    for i in range(Y):\n",
    "        for j in range(X):\n",
    "            value = values[i, j]\n",
    "            color = 'black' if value > max_val/2 else 'white'\n",
    "            text = ax.text(j, i, f'{value:.3f}', ha=\"center\", va=\"center\", color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Dataset loaded from dataset_patched\n",
      "Dataset loaded from dataset_full_images\n",
      "Using model: FasterRCNN\n"
     ]
    }
   ],
   "source": [
    "# Device Selection\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Random Seed for Dataset split\n",
    "SEED = 1\n",
    "np_generator = np.random.default_rng(SEED)\n",
    "\n",
    "# Dataset split\n",
    "DATASET_FRACTION = 1\n",
    "VALIDATION_FRACTION = 0.2\n",
    "dataset = AleketDataset(download_dataset(\"dataset_patched\", \"\"))\n",
    "full_dataset = AleketDataset(download_dataset(\"dataset_full_images\", \"\"))\n",
    "train_set, val_set = split_dataset(dataset, DATASET_FRACTION, VALIDATION_FRACTION, np_generator)\n",
    "\n",
    "# Model\n",
    "model = get_model(device, trainable_backbone_layers=3)\n",
    "\n",
    "print(f\"Using model: {model._get_name()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train parameters for 'ac_run1_v2_tb=3'\n"
     ]
    }
   ],
   "source": [
    "RUN_NAME = \"ac_run1_v2_tb=3\"\n",
    "\n",
    "TRAIN_COMPLETE = False\n",
    "params = RunParams(\n",
    "    run_name=RUN_NAME,\n",
    "    batch_size=4,\n",
    "    dataloader_workers=4, \n",
    "    total_epochs=100,\n",
    "    augmentation={  \n",
    "        \"horizontal_flip\": {\n",
    "            \"p\": 0.5\n",
    "        },\n",
    "        \"vertical_flip\": {\n",
    "            \"p\": 0.5\n",
    "        },\n",
    "        \"scale_jitter\": {\n",
    "            \"target_size\": (1024, 1024),\n",
    "            \"scale_range\": (0.8, 1.2)\n",
    "        },\n",
    "        \"perspective\": {\n",
    "            \"distortion_scale\": 0.1,\n",
    "            \"p\": 0.5\n",
    "        },\n",
    "        \"rotation\": {\n",
    "            \"degrees\": 30,\n",
    "            \"expand\": True\n",
    "        },\n",
    "        \"color_jitter\": {\n",
    "            \"brightness\": 1,\n",
    "            \"contrast\": 0.1,\n",
    "            \"saturation\": 0.05\n",
    "        }\n",
    "    },\n",
    "    optimizer={\n",
    "        \"lr\": 0.005,\n",
    "        \"momentum\": 0.9,\n",
    "        \"weight_decay\": 0.00005\n",
    "    },\n",
    "    lr_scheduler={\n",
    "        \"factor\": 0.5,\n",
    "        \"patience\": 10,\n",
    "        \"min_lr\": 0.0001\n",
    "    },\n",
    "    validation_set=val_set,\n",
    "    train_set=train_set\n",
    "    )\n",
    "\n",
    "\n",
    "print(f\"Train parameters for '{RUN_NAME}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_params = parse_params(params, model, dataset)\n",
    "train_dataloader = parsed_params[\"train_loader\"]\n",
    "val_dataloader = parsed_params[\"val_loader\"]\n",
    "augmentation = parsed_params[\"augmentation\"]\n",
    "\n",
    "count_analyze(full_dataset, save_folder=\"full_dataset_statistics\")\n",
    "count_analyze(dataset, save_folder=\"patched_dataset_statistics\")\n",
    "count_analyze(dataset, indices=train_dataloader.dataset.indices, save_folder=\"patched_train_dataset_statistics\")\n",
    "count_analyze(dataset, indices=val_dataloader.dataset.indices, save_folder=\"patched_val_dataset_statistics\")\n",
    "\n",
    "dataset.augmentation = augmentation\n",
    "augment_example(train_dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-23T09:16:28.489606Z",
     "start_time": "2024-10-23T09:04:42.842532Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G9UdbXiJIAzZ",
    "outputId": "4eaac050-8192-4ffe-e5ae-ee59701ce7b2"
   },
   "outputs": [],
   "source": [
    "train(model, dataset, params, device, checkpoints=True)\n",
    "clear_output(wait=False)\n",
    "print(\"TRAIN COMPLETE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = RunParams()\n",
    "params.load(os.path.join('results', RUN_NAME, \"params.json\")) # override parameters\n",
    "train(model, dataset, params, device, checkpoints=True, resume=True, verbose=True)\n",
    "clear_output(wait=False)\n",
    "print(\"TRAIN COMPLETE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_NAME_TO_TEST = RUN_NAME\n",
    "\n",
    "\n",
    "run_dir = os.path.join(\"results\", RUN_NAME_TO_TEST)\n",
    "params_path = os.path.join(run_dir, \"params.json\")\n",
    "checkpoint_path = os.path.join(run_dir,\"checkpoints\", \"best.pth\")\n",
    "\n",
    "model = get_model(device)\n",
    "params = RunParams()\n",
    "params.load(params_path)\n",
    "\n",
    "val_indices = full_dataset.to_indices(params.validation_set.keys())\n",
    "model = load_checkpoint(model, checkpoint_path)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = Predictor(\n",
    "    model,\n",
    "    device,\n",
    "    detections_per_patch=150,\n",
    "    detections_per_image=300,\n",
    "    images_per_batch=2,\n",
    "    image_size_factor=0.8,\n",
    "    patches_per_batch=8,\n",
    ")\n",
    "\n",
    "nms_thrs = np.round(np.flip(np.arange(0.2, 0.5 + 1e-3, 0.1)),2)\n",
    "score_thrs = np.round(np.arange(0.1, 0.8 + 1e-4, 0.05),2)\n",
    "\n",
    "np.savetxt(os.path.join(run_dir,\"nms_thrs.csv\"), nms_thrs, delimiter=',', fmt='%.2f')\n",
    "np.savetxt(os.path.join(run_dir,\"score_thrs.csv\"), score_thrs, delimiter=',', fmt='%.2f')\n",
    "\n",
    "N = len(nms_thrs)\n",
    "S = len(score_thrs)\n",
    "\n",
    "eval = Evaluator(full_dataset, val_indices,)\n",
    "\n",
    "results_ap  = np.full((N,S), -1.0)\n",
    "results_aad = np.full((N,S), -1.0)\n",
    "results_acd = np.full((N,S), -1.0)\n",
    "\n",
    "for i, n in enumerate(nms_thrs):\n",
    "    for j, s in tqdm(enumerate(score_thrs), total=S):\n",
    "        try:\n",
    "            stats = predictor.eval_dataset(full_dataset, val_indices, n, s, eval)\n",
    "            results_ap[i, j] = stats[VALIDATION_METRICS[0]]\n",
    "            results_acd[i, j] = stats[VALIDATION_METRICS[-2]]\n",
    "            results_aad[i, j] = stats[VALIDATION_METRICS[-1]]\n",
    "        except Exception as e:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(os.path.join(run_dir,\"ap_analysis.csv\"), results_ap, delimiter=',', fmt='%.4f')\n",
    "np.savetxt(os.path.join(run_dir,\"aad_analysis.csv\"), results_aad, delimiter=',', fmt='%.4f')\n",
    "np.savetxt(os.path.join(run_dir,\"acd_analysis.csv\"), results_acd, delimiter=',', fmt='%.4f')\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(60, 10))\n",
    "\n",
    "draw_heat_map(\"AP\",  results_ap, axes[0], score_thrs, nms_thrs)\n",
    "draw_heat_map(\"AAD\", results_aad, axes[1],score_thrs, nms_thrs)\n",
    "draw_heat_map(\"ACD\", results_acd, axes[2],score_thrs, nms_thrs)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m infer_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(run_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(infer_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 16\u001b[0m \u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minfer_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnms_thresh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscore_thresh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_of_annotated_images_to_save\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_bboxes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/users/maksi/Documents/AleketML/.wslvenv/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/users/maksi/Documents/AleketML/predictor.py:258\u001b[0m, in \u001b[0;36mPredictor.infer\u001b[0;34m(self, images, output_dir, nms_thresh, score_thresh, save_bboxes, num_of_annotated_images_to_save)\u001b[0m\n\u001b[1;32m    255\u001b[0m headers\u001b[38;5;241m.\u001b[39mextend([\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m count\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m class_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses])\n\u001b[1;32m    256\u001b[0m stats_writer\u001b[38;5;241m.\u001b[39mwriterow(headers)\n\u001b[0;32m--> 258\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnms_thresh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore_thresh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, pred \u001b[38;5;129;01min\u001b[39;00m predictions\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    260\u001b[0m     image \u001b[38;5;241m=\u001b[39m images[idx]\n",
      "File \u001b[0;32m/mnt/c/users/maksi/Documents/AleketML/.wslvenv/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/users/maksi/Documents/AleketML/predictor.py:178\u001b[0m, in \u001b[0;36mPredictor.get_predictions\u001b[0;34m(self, images, nms_thresh, score_thresh)\u001b[0m\n\u001b[1;32m    176\u001b[0m     b_imgs \u001b[38;5;241m=\u001b[39m b_imgs\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautocast(device_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16):\n\u001b[0;32m--> 178\u001b[0m         predictions\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb_imgs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    179\u001b[0m predictions \u001b[38;5;241m=\u001b[39m patcher\u001b[38;5;241m.\u001b[39mpostprocess(patches, predictions, nms_thresh, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mper_image_detections)\n\u001b[1;32m    180\u001b[0m result[idx] \u001b[38;5;241m=\u001b[39m predictions\n",
      "File \u001b[0;32m/mnt/c/users/maksi/Documents/AleketML/.wslvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/users/maksi/Documents/AleketML/.wslvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/c/users/maksi/Documents/AleketML/.wslvenv/lib/python3.10/site-packages/torchvision/models/detection/generalized_rcnn.py:105\u001b[0m, in \u001b[0;36mGeneralizedRCNN.forward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m    103\u001b[0m     features \u001b[38;5;241m=\u001b[39m OrderedDict([(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m, features)])\n\u001b[1;32m    104\u001b[0m proposals, proposal_losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrpn(images, features, targets)\n\u001b[0;32m--> 105\u001b[0m detections, detector_losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroi_heads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproposals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m detections \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform\u001b[38;5;241m.\u001b[39mpostprocess(detections, images\u001b[38;5;241m.\u001b[39mimage_sizes, original_image_sizes)  \u001b[38;5;66;03m# type: ignore[operator]\u001b[39;00m\n\u001b[1;32m    108\u001b[0m losses \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/mnt/c/users/maksi/Documents/AleketML/.wslvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/c/users/maksi/Documents/AleketML/.wslvenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/c/users/maksi/Documents/AleketML/.wslvenv/lib/python3.10/site-packages/torchvision/models/detection/roi_heads.py:775\u001b[0m, in \u001b[0;36mRoIHeads.forward\u001b[0;34m(self, features, proposals, image_shapes, targets)\u001b[0m\n\u001b[1;32m    773\u001b[0m     losses \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss_classifier\u001b[39m\u001b[38;5;124m\"\u001b[39m: loss_classifier, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss_box_reg\u001b[39m\u001b[38;5;124m\"\u001b[39m: loss_box_reg}\n\u001b[1;32m    774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 775\u001b[0m     boxes, scores, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpostprocess_detections\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclass_logits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbox_regression\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproposals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    776\u001b[0m     num_images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(boxes)\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_images):\n",
      "File \u001b[0;32m/mnt/c/users/maksi/Documents/AleketML/.wslvenv/lib/python3.10/site-packages/torchvision/models/detection/roi_heads.py:680\u001b[0m, in \u001b[0;36mRoIHeads.postprocess_detections\u001b[0;34m(self, class_logits, box_regression, proposals, image_shapes)\u001b[0m\n\u001b[1;32m    677\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m class_logits\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    679\u001b[0m boxes_per_image \u001b[38;5;241m=\u001b[39m [boxes_in_image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m boxes_in_image \u001b[38;5;129;01min\u001b[39;00m proposals]\n\u001b[0;32m--> 680\u001b[0m pred_boxes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbox_coder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbox_regression\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproposals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m pred_scores \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(class_logits, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    684\u001b[0m pred_boxes_list \u001b[38;5;241m=\u001b[39m pred_boxes\u001b[38;5;241m.\u001b[39msplit(boxes_per_image, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/mnt/c/users/maksi/Documents/AleketML/.wslvenv/lib/python3.10/site-packages/torchvision/models/detection/_utils.py:178\u001b[0m, in \u001b[0;36mBoxCoder.decode\u001b[0;34m(self, rel_codes, boxes)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m box_sum \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    177\u001b[0m     rel_codes \u001b[38;5;241m=\u001b[39m rel_codes\u001b[38;5;241m.\u001b[39mreshape(box_sum, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 178\u001b[0m pred_boxes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrel_codes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcat_boxes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m box_sum \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    180\u001b[0m     pred_boxes \u001b[38;5;241m=\u001b[39m pred_boxes\u001b[38;5;241m.\u001b[39mreshape(box_sum, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m4\u001b[39m)\n",
      "File \u001b[0;32m/mnt/c/users/maksi/Documents/AleketML/.wslvenv/lib/python3.10/site-packages/torchvision/models/detection/_utils.py:216\u001b[0m, in \u001b[0;36mBoxCoder.decode_single\u001b[0;34m(self, rel_codes, boxes)\u001b[0m\n\u001b[1;32m    213\u001b[0m pred_h \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(dh) \u001b[38;5;241m*\u001b[39m heights[:, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    215\u001b[0m \u001b[38;5;66;03m# Distance from center to box's corner.\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m c_to_c_h \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred_ctr_y\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred_h\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m pred_h\n\u001b[1;32m    217\u001b[0m c_to_c_w \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0.5\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mpred_ctr_x\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mpred_w\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;241m*\u001b[39m pred_w\n\u001b[1;32m    219\u001b[0m pred_boxes1 \u001b[38;5;241m=\u001b[39m pred_ctr_x \u001b[38;5;241m-\u001b[39m c_to_c_w\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "predictor = Predictor(\n",
    "    model,\n",
    "    device,\n",
    "    detections_per_patch=150,\n",
    "    detections_per_image=300,\n",
    "    image_size_factor=1,\n",
    "    images_per_batch=1,\n",
    "    patches_per_batch=1,\n",
    ")\n",
    "\n",
    "image_list = [os.path.join(f\"{full_dataset.img_dir}\",f\"{name}.jpeg\") for name in params.validation_set.keys()]\n",
    "\n",
    "infer_dir = os.path.join(run_dir, \"infer\")\n",
    "os.makedirs(infer_dir, exist_ok=True)\n",
    "\n",
    "predictor.infer(\n",
    "    images=image_list,\n",
    "    output_dir=infer_dir,\n",
    "    nms_thresh=0.2,\n",
    "    score_thresh=0.5,\n",
    "    num_of_annotated_images_to_save=10,\n",
    "    save_bboxes=False,    \n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "https://github.com/maximusjv/AleketML/blob/main/aleket.ipynb",
     "timestamp": 1726685419266
    }
   ]
  },
  "kernelspec": {
   "display_name": ".wslvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
