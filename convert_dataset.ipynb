{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO - DESCRIBE THIS FILE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import make_patches\n",
    "# Install Pillow if not already installed\n",
    "%pip install pillow  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Library\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import shutil\n",
    "from typing import Any, NewType\n",
    "import csv \n",
    "\n",
    "# Third-Party Libraries\n",
    "from PIL import Image, ImageDraw\n",
    "from PIL.TiffTags import TAGS\n",
    "\n",
    "# Type Alias for Bounding Boxes\n",
    "Box = NewType('Box', tuple[int, int, int, int])\n",
    "\n",
    "# Dataset Paths (Remember to replace placeholders with your actual paths)\n",
    "DATASET_SOURCE = os.path.join( \"/mnt\", \"f\", \"dataUtils\", \"raw_data\")  # FIXME: Change accordingly\n",
    "OUTPUT_DATASET = os.path.join( \"/mnt\", \"e\", \"dataset\")   # FIXME: Change accordingly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Math utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils\n",
    "def get_image_metadata(img: Image) -> dict[str, float]:\n",
    "    \"\"\"Extracts resolution metadata from a TIFF image.\n",
    "    Args:\n",
    "        img: A PIL Image object.\n",
    "    Returns:\n",
    "        A dictionary containing resolution information (x, y, and unit).\n",
    "    \"\"\"\n",
    "    tiff_tags = {TAGS.get(tag, tag): value for tag, value in img.tag.items()}\n",
    "        \n",
    "    res = {\n",
    "        \"x_resolution\": tiff_tags['XResolution'][0][0]/tiff_tags['XResolution'][0][1],\n",
    "        \"y_resolution\": tiff_tags['YResolution'][0][0]/tiff_tags['YResolution'][0][1],\n",
    "        \"resolution_unit\": tiff_tags['ResolutionUnit'] \n",
    "    }\n",
    "    return res\n",
    "\n",
    "class ImageUtils:\n",
    "    \"\"\"Provides utility functions for working with image resolutions and areas.\"\"\"\n",
    "\n",
    "    def __init__(self, img):\n",
    "        self.img = img\n",
    "        self.metadata = get_image_metadata(img)\n",
    "        self.x_resolution = float(self.metadata[\"x_resolution\"])\n",
    "        self.y_resolution = float(self.metadata[\"y_resolution\"])\n",
    "\n",
    "    def area_units_to_pixels(self, area):\n",
    "        \"\"\"Converts area from resolution units to pixels.\"\"\"\n",
    "        return float(area) * (max(self.x_resolution, self.y_resolution) ** 2)\n",
    "\n",
    "    def area_pixels_to_units(self, area):\n",
    "        \"\"\"Converts area from pixels to resolution units.\"\"\"\n",
    "        return float(area) / (max(self.x_resolution, self.y_resolution) ** 2)\n",
    "\n",
    "\n",
    "class ImageUtilOpener:\n",
    "    \"\"\"Context manager for opening and working with an image.\"\"\"\n",
    "\n",
    "    def __init__(self, file_name):\n",
    "        self.file_name = file_name\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.img = Image.open(self.file_name)\n",
    "        return ImageUtils(self.img)\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        self.img.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read csv+tif ImageJ-created dataset, and convert to dict\n",
    "of images_path as keys and corresponding bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing row in /mnt/f/dataUtils/raw_data/csv/10 (2).tifall.tif.csv: too many values to unpack (expected 5)\n",
      "/mnt/f/dataUtils/raw_data/csv/10 (2).tifall.tif.csv Failed\n",
      "WARNING: Duplicate bbox found in 20 (2).tifall: (4666, 4555, 4696, 4585)\n",
      "WARNING: Duplicate bbox found in 22 (2): (845, 4136, 1128, 4419)\n",
      "WARNING: Duplicate bbox found in 45 (3).tifall: (1859, 5290, 1926, 5357)\n",
      "WARNING: Duplicate bbox found in 45 (4).tifall: (1646, 3555, 1888, 3797)\n",
      "ERROR: Same bbox with different label found in 53 (6).tifall: (2119, 4764, 2157, 4802)\n",
      "WARNING: Duplicate bbox found in 63 (3).tifall: (4760, 3211, 4861, 3312)\n",
      "WARNING: Duplicate bbox found in 64.tifall: (3762, 1486, 3804, 1528)\n",
      "WARNING: Duplicate bbox found in 64.tifall: (3762, 1486, 3804, 1528)\n",
      "WARNING: Duplicate bbox found in 64.tifall: (3762, 1486, 3804, 1528)\n",
      "WARNING: Duplicate bbox found in 64.tifall: (3762, 1486, 3804, 1528)\n",
      "WARNING: Duplicate bbox found in 64.tifall: (3762, 1486, 3804, 1528)\n",
      "WARNING: Duplicate bbox found in 64.tifall: (3762, 1486, 3804, 1528)\n",
      "WARNING: Duplicate bbox found in 64.tifall: (3762, 1486, 3804, 1528)\n",
      "WARNING: Duplicate bbox found in 64.tifall: (3762, 1486, 3804, 1528)\n",
      "WARNING: Duplicate bbox found in 64.tifall: (3762, 1486, 3804, 1528)\n",
      "WARNING: Duplicate bbox found in 64.tifall: (3762, 1486, 3804, 1528)\n",
      "WARNING: Duplicate bbox found in 64.tifall: (3762, 1486, 3804, 1528)\n",
      "WARNING: Duplicate bbox found in 64.tifall: (3762, 1486, 3804, 1528)\n",
      "WARNING: Duplicate bbox found in 64.tifall: (3762, 1486, 3804, 1528)\n",
      "WARNING: Duplicate bbox found in 64.tifall: (3762, 1486, 3804, 1528)\n",
      "WARNING: Duplicate bbox found in 64.tifall: (3762, 1486, 3804, 1528)\n",
      "WARNING: Duplicate bbox found in 64.tifall: (3762, 1486, 3804, 1528)\n",
      "WARNING: Duplicate bbox found in 64.tifall: (3762, 1486, 3804, 1528)\n",
      "WARNING: Duplicate bbox found in 64.tifall: (3762, 1486, 3804, 1528)\n",
      "WARNING: Duplicate bbox found in 64.tifall: (3762, 1486, 3804, 1528)\n",
      "WARNING: Duplicate bbox found in 64.tifall: (3762, 1486, 3804, 1528)\n",
      "WARNING: Duplicate bbox found in 64.tifall: (3762, 1486, 3804, 1528)\n",
      "WARNING: Duplicate bbox found in 64.tifall: (3762, 1486, 3804, 1528)\n",
      "WARNING: Duplicate bbox found in 65 (2): (5196, 1519, 5207, 1530)\n",
      "WARNING: Duplicate bbox found in 65 (2): (5196, 1519, 5207, 1530)\n",
      "WARNING: Duplicate bbox found in 65 (2): (5196, 1519, 5207, 1530)\n",
      "WARNING: Duplicate bbox found in 65 (2): (5196, 1519, 5207, 1530)\n",
      "WARNING: Duplicate bbox found in 65 (2): (5196, 1519, 5207, 1530)\n",
      "WARNING: Duplicate bbox found in 65 (2): (5196, 1519, 5207, 1530)\n",
      "WARNING: Duplicate bbox found in 65 (2): (5196, 1519, 5207, 1530)\n",
      "WARNING: Duplicate bbox found in 65 (2): (5196, 1519, 5207, 1530)\n",
      "WARNING: Duplicate bbox found in 65 (2): (5196, 1519, 5207, 1530)\n",
      "WARNING: Duplicate bbox found in 65 (2): (5196, 1519, 5207, 1530)\n",
      "WARNING: Duplicate bbox found in 65 (2): (5196, 1519, 5207, 1530)\n",
      "WARNING: Duplicate bbox found in 65 (2): (5196, 1519, 5207, 1530)\n",
      "WARNING: Duplicate bbox found in 65 (2): (5196, 1519, 5207, 1530)\n",
      "WARNING: Duplicate bbox found in 65 (2): (5196, 1519, 5207, 1530)\n",
      "WARNING: Duplicate bbox found in 65 (2): (4340, 5073, 4474, 5207)\n",
      "WARNING: Duplicate bbox found in 68 (2): (3221, 4480, 3292, 4551)\n",
      "ERROR: Same bbox with different label found in 76.tifall: (4646, 3281, 4684, 3319)\n",
      "WARNING: Duplicate bbox found in 77 (2).tifall: (4085, 4223, 4142, 4280)\n",
      "WARNING: Duplicate bbox found in 77 (2).tifall: (4085, 4223, 4142, 4280)\n",
      "WARNING: Duplicate bbox found in 77 (2).tifall: (4085, 4223, 4142, 4280)\n",
      "WARNING: Duplicate bbox found in 77 (2).tifall: (4085, 4223, 4142, 4280)\n",
      "WARNING: Duplicate bbox found in 77 (2).tifall: (4085, 4223, 4142, 4280)\n",
      "WARNING: Duplicate bbox found in 77 (2).tifall: (4085, 4223, 4142, 4280)\n",
      "WARNING: Duplicate bbox found in 77 (2).tifall: (4085, 4223, 4142, 4280)\n",
      "WARNING: Duplicate bbox found in 77 (2).tifall: (4085, 4223, 4142, 4280)\n",
      "WARNING: Duplicate bbox found in 77 (2).tifall: (4085, 4223, 4142, 4280)\n",
      "WARNING: Duplicate bbox found in 77 (2).tifall: (4085, 4223, 4142, 4280)\n",
      "WARNING: Duplicate bbox found in 77 (2).tifall: (4085, 4223, 4142, 4280)\n",
      "WARNING: Duplicate bbox found in 77 (2).tifall: (4085, 4223, 4142, 4280)\n",
      "WARNING: Duplicate bbox found in 77 (2).tifall: (4085, 4223, 4142, 4280)\n",
      "WARNING: Duplicate bbox found in 77 (2).tifall: (4085, 4223, 4142, 4280)\n",
      "WARNING: Duplicate bbox found in 77 (2).tifall: (4085, 4223, 4142, 4280)\n",
      "WARNING: Duplicate bbox found in 77 (2).tifall: (4085, 4223, 4142, 4280)\n",
      "WARNING: Duplicate bbox found in 77 (2).tifall: (4085, 4223, 4142, 4280)\n",
      "WARNING: Duplicate bbox found in 77 (2).tifall: (4085, 4223, 4142, 4280)\n",
      "WARNING: Duplicate bbox found in 77 (2).tifall: (4085, 4223, 4142, 4280)\n",
      "WARNING: Duplicate bbox found in 77 (2).tifall: (4085, 4223, 4142, 4280)\n",
      "WARNING: Duplicate bbox found in 77 (2).tifall: (4085, 4223, 4142, 4280)\n",
      "WARNING: Duplicate bbox found in 77 (2).tifall: (4085, 4223, 4142, 4280)\n",
      "WARNING: Duplicate bbox found in 77 (2).tifall: (4085, 4223, 4142, 4280)\n",
      "WARNING: Duplicate bbox found in 77 (2).tifall: (4085, 4223, 4142, 4280)\n",
      "WARNING: Duplicate bbox found in 77 (2).tifall: (4085, 4223, 4142, 4280)\n",
      "WARNING: Duplicate bbox found in 77 (2).tifall: (4085, 4223, 4142, 4280)\n",
      "WARNING: Duplicate bbox found in 77 (2).tifall: (4085, 4223, 4142, 4280)\n",
      "WARNING: Duplicate bbox found in 77 (2).tifall: (4085, 4223, 4142, 4280)\n",
      "WARNING: Duplicate bbox found in 77 (2).tifall: (4085, 4223, 4142, 4280)\n",
      "WARNING: Duplicate bbox found in 77 (2).tifall: (4085, 4223, 4142, 4280)\n",
      "WARNING: Duplicate bbox found in 77 (2).tifall: (4085, 4223, 4142, 4280)\n",
      "WARNING: Duplicate bbox found in 77 (2).tifall: (4085, 4223, 4142, 4280)\n",
      "WARNING: Duplicate bbox found in 77.tifall: (5989, 4453, 6019, 4483)\n",
      "WARNING: Duplicate bbox found in 80.tifall: (6448, 3822, 6508, 3882)\n",
      "WARNING: Duplicate bbox found in 82.tifall: (1801, 2543, 1843, 2585)\n",
      "WARNING: Duplicate bbox found in 90 (4): (658, 1043, 762, 1147)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (3127, 1556, 3171, 1600)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (2945, 1626, 3014, 1695)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (2912, 1703, 2956, 1747)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (2827, 1279, 2865, 1317)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (2822, 1251, 2844, 1273)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (2820, 1165, 2842, 1187)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (2783, 1167, 2808, 1192)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (2576, 801, 2616, 841)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (2599, 893, 2654, 948)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (2520, 1103, 2574, 1157)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (2490, 1161, 2528, 1199)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (2506, 1141, 2534, 1169)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (2441, 1075, 2496, 1130)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (2466, 1047, 2488, 1069)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (2388, 1301, 2424, 1337)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (2321, 1250, 2369, 1298)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (1447, 862, 1505, 920)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (1508, 886, 1541, 919)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (1417, 804, 1472, 859)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (820, 1054, 832, 1066)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (713, 1058, 731, 1076)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (668, 942, 712, 986)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (556, 657, 596, 697)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (517, 651, 553, 687)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (495, 652, 520, 677)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (371, 780, 409, 818)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (344, 814, 375, 845)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (438, 861, 466, 889)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (225, 864, 256, 895)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (198, 907, 223, 932)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (340, 1036, 368, 1064)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (265, 1057, 301, 1093)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (473, 928, 504, 959)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (504, 958, 537, 991)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (472, 1014, 490, 1032)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (294, 1174, 316, 1196)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (343, 1198, 365, 1220)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (387, 1110, 399, 1122)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (421, 1129, 433, 1141)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (446, 1110, 464, 1128)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (402, 1051, 420, 1069)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (471, 1147, 481, 1157)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (557, 1107, 569, 1119)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (566, 1093, 584, 1111)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (571, 1125, 581, 1135)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (442, 1309, 454, 1321)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (462, 1323, 473, 1334)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (551, 1342, 569, 1360)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (551, 1303, 561, 1313)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (538, 1293, 548, 1303)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (529, 1331, 541, 1343)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (517, 1372, 527, 1382)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (491, 1375, 509, 1393)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (310, 1232, 321, 1243)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (320, 1406, 342, 1428)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (233, 1475, 255, 1497)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (395, 1483, 407, 1495)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (300, 1548, 312, 1560)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (333, 1618, 344, 1629)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (335, 1650, 347, 1662)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (401, 1597, 419, 1615)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (442, 1572, 452, 1582)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (463, 1586, 472, 1595)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (522, 1617, 534, 1629)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (434, 1637, 445, 1648)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (475, 1689, 485, 1699)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (617, 1454, 639, 1476)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (893, 1413, 905, 1425)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (757, 1640, 779, 1662)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (742, 1675, 760, 1693)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (651, 1782, 673, 1804)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (657, 1807, 679, 1829)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (551, 1875, 616, 1940)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (435, 1892, 492, 1949)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (396, 1796, 438, 1838)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (164, 1857, 208, 1901)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (1288, 1673, 1319, 1704)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (1522, 1561, 1555, 1594)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (1445, 1486, 1467, 1508)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (1478, 1599, 1518, 1639)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (1526, 1601, 1544, 1619)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (1352, 1859, 1400, 1907)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (1454, 1883, 1472, 1901)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (1518, 1926, 1556, 1964)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (1567, 1881, 1585, 1899)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (1563, 1834, 1603, 1874)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (1602, 1825, 1614, 1837)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (1246, 2096, 1294, 2144)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (1075, 2149, 1093, 2167)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (1776, 1973, 1809, 2006)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (1874, 1956, 1892, 1974)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (1961, 1753, 2013, 1805)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (1938, 1796, 1971, 1829)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (2059, 2035, 2097, 2073)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (2122, 2054, 2147, 2079)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (2063, 1958, 2096, 1991)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (1660, 2469, 1685, 2494)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (1835, 2513, 1860, 2538)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (1986, 2535, 2051, 2600)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (2013, 2608, 2051, 2646)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (2061, 2603, 2103, 2645)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (2133, 2550, 2173, 2590)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (2176, 2545, 2212, 2581)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (2214, 2627, 2236, 2649)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (2161, 2642, 2173, 2654)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (2480, 2591, 2502, 2613)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (2667, 2799, 2692, 2824)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (2691, 2773, 2719, 2801)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (2734, 2784, 2772, 2822)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (2794, 2704, 2819, 2729)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (2820, 2742, 2848, 2770)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (2958, 2672, 2991, 2705)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (2968, 2585, 2999, 2616)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (3129, 2277, 3162, 2310)\n",
      "WARNING: Duplicate bbox found in 104.tifall: (3105, 2238, 3141, 2274)\n",
      "Error processing row in /mnt/f/dataUtils/raw_data/csv/110.tif.csv: too many values to unpack (expected 5)\n",
      "/mnt/f/dataUtils/raw_data/csv/110.tif.csv Failed\n",
      "WARNING: Duplicate bbox found in 180 (2).tifall: (2774, 3732, 2798, 3756)\n",
      "WARNING: Duplicate bbox found in 220 (2).tifall: (3336, 2646, 3417, 2727)\n",
      "ERROR: Same bbox with different label found in 221 (2).tifall: (3940, 1918, 3989, 1967)\n",
      "ERROR: Same bbox with different label found in 221 (2).tifall: (3931, 2198, 3975, 2242)\n",
      "Finished converting\n"
     ]
    }
   ],
   "source": [
    "def convert_cxcywh_to_xyxy(box: Box) -> Box:\n",
    "    \"\"\"Converts a bounding box from center-x, center-y, width, height format (CXCYWH) \n",
    "    to top-left-x, top-left-y, bottom-right-x, bottom-right-y format (XYXY).\n",
    "    Args:\n",
    "        box: A tuple representing the bounding box in CXCYWH format.\n",
    "    Returns:\n",
    "        A tuple representing the bounding box in XYXY format.\n",
    "    \"\"\"\n",
    "    cx, cy, w, h = box\n",
    "    xmin = cx-w//2\n",
    "    ymin = cy-h//2\n",
    "    xmax = cx+(w+1)//2  # ceil\n",
    "    ymax = cy+(h+1)//2  # ceil\n",
    "    return xmin, ymin, xmax, ymax\n",
    "\n",
    "def sanitize_annotations(name:str, annotation: dict[str, Any]) -> None:\n",
    "    \"\"\"Sanitizes annotations by removing duplicates and invalid bounding boxes.\n",
    "\n",
    "    Args:\n",
    "        name: The name of the image associated with the annotations.\n",
    "        annotations: A dictionary containing \"category_id\" and \"boxes\" lists.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing sanitized \"category_id\" and \"boxes\" lists.\n",
    "    \"\"\"\n",
    "    sanitized_annotations = {\n",
    "        \"category_id\": [],\n",
    "        \"boxes\": []\n",
    "    }\n",
    "    \n",
    "    bbox_dict = dict()\n",
    "    for label, bbox in zip(annotation[\"category_id\"], annotation[\"boxes\"]):\n",
    "        if bbox in bbox_dict:\n",
    "            if bbox_dict[bbox] == label:\n",
    "                print(f\"WARNING: Duplicate bbox found in {name}: {bbox}\")\n",
    "            else:\n",
    "                print(f\"ERROR: Same bbox with different label found in {name}: {bbox}\")\n",
    "            continue\n",
    "        if any(coord < 0 for coord in bbox):\n",
    "            print(f\"Corrupted box found in {name}: {bbox}\")\n",
    "            continue\n",
    "\n",
    "        bbox_dict[bbox] = label\n",
    "\n",
    "    for key in bbox_dict:\n",
    "        sanitized_annotations[\"category_id\"].append(bbox_dict[key])\n",
    "        sanitized_annotations[\"boxes\"].append(key)\n",
    "\n",
    "    return sanitized_annotations\n",
    "        \n",
    "def convert_annotations(csv_path: str, img_path: str) -> dict[str, Any]:\n",
    "    \"\"\"Converts a CSV file and an image into annotations.\n",
    "    Args:\n",
    "        csv_path: The path to the CSV file containing annotations.\n",
    "        img_path: The path to the image file.\n",
    "    Returns:\n",
    "        A dictionary containing \"category_id\" and \"boxes\" lists representing the annotations.\n",
    "    \"\"\"\n",
    "    annotations = {}\n",
    "    name = os.path.basename(img_path).removesuffix(\".tif\")\n",
    "    annotations = {\n",
    "        \"category_id\": [],\n",
    "        \"boxes\": []\n",
    "    }\n",
    "    \n",
    "    with ImageUtilOpener(img_path) as util:\n",
    "        if os.path.exists(csv_path): \n",
    "            with open(csv_path) as data_file:\n",
    "                data = csv.reader(data_file)\n",
    "                next(data) # Skip header row\n",
    "                for row in data:\n",
    "                    try:\n",
    "                        _, label, area, category_id, _ = row  # Unpack row, ignore filename and category_name\n",
    "                        _, coordinates = label.split(':')  # Extract coordinates from label\n",
    "                        y, x = coordinates.split('-')\n",
    "                        y, x = int(y), int(x)\n",
    "\n",
    "                        area_in_pixels = util.area_units_to_pixels(float(area))\n",
    "                        bbox_side = int(math.sqrt(area_in_pixels / math.pi) * 2)  # Calculate square side length\n",
    "\n",
    "                        bbox = convert_cxcywh_to_xyxy((x, y, bbox_side, bbox_side))\n",
    "                        annotations[\"category_id\"].append(int(category_id))\n",
    "                        annotations[\"boxes\"].append(bbox)\n",
    "                    except Exception as e:\n",
    "                        \n",
    "                        annotations[\"boxes\"] = []\n",
    "                        annotations[\"category_id\"] = []\n",
    "                        print(f\"Error processing row in {csv_path}: {e}\")\n",
    "                        print(f\"{csv_path} Failed\")\n",
    "                        break  \n",
    "                     \n",
    "    return annotations\n",
    "    \n",
    "    \n",
    "def convert_dataset(data_path: str, imgs_path: str, res_path: str, replace_imgs=True):\n",
    "    \"\"\"Converts a dataset from the source format to the desired output format.\n",
    "    Args:\n",
    "        data_path: The path to the directory containing CSV annotation files\n",
    "        imgs_path: The path to the directory containing image files\n",
    "        res_path: The path to the output directory where the converted dataset will be saved\n",
    "        replace_imgs: Whether to replace existing images in the output directory\n",
    "    \"\"\"\n",
    "    img_list = [\n",
    "        os.path.splitext(f)[0] \n",
    "        for f in os.listdir(imgs_path) \n",
    "        if os.path.isfile(os.path.join(imgs_path, f)) and f.endswith(\".tif\")\n",
    "    ]\n",
    "    \n",
    "    if replace_imgs:\n",
    "        try:\n",
    "            shutil.rmtree(res_path)\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "\n",
    "    os.makedirs(os.path.join(res_path, \"imgs\"), exist_ok=True)\n",
    "       \n",
    "    dataset = {}\n",
    "    image_id = 1  # Start image IDs from 1\n",
    "    \n",
    "    for name in img_list:\n",
    "        csv_path = f'{data_path}/{name}.tif.csv'\n",
    "        img_path = f'{imgs_path}/{name}.tif'\n",
    "        annotations = convert_annotations(csv_path, img_path)\n",
    "        if not annotations[\"boxes\"]:\n",
    "            continue # Skip images without annotations\n",
    "\n",
    "        if replace_imgs:\n",
    "            img = Image.open(img_path)\n",
    "            img.save(os.path.join(res_path, \"imgs\", f\"{image_id}.jpeg\"), quality=100)\n",
    "        \n",
    "        annotations = sanitize_annotations(name, annotations)\n",
    "        dataset[str(image_id)] = annotations\n",
    "        \n",
    "        image_id += 1\n",
    "\n",
    "    with open(os.path.join(res_path, \"dataset.json\"), \"w\") as outfile:\n",
    "        json.dump(dataset, outfile, indent=1)\n",
    "    print(\"Finished converting\")\n",
    "    \n",
    "convert_dataset(f\"{DATASET_SOURCE}/csv\", f\"{DATASET_SOURCE}/imgs\", OUTPUT_DATASET, replace_imgs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Patch dataset into images of desired size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_area(box: Box) -> float:\n",
    "    \"\"\"Calculates the box area\n",
    "    Args:\n",
    "        box: The box in XYXY format.\n",
    "\n",
    "    Returns:\n",
    "        The area of the box.\n",
    "    \"\"\"\n",
    "    x1, y1, x2, y2 = box\n",
    "    area = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "    return max(0, x2 - x1) * max(0, y2 - y1)\n",
    "    \n",
    "\n",
    "def patch_annots(\n",
    "         cropped_img: Image.Image,\n",
    "         crop_box: Box,\n",
    "         annots: dict[str, Any],\n",
    "         crop_tolerance: float,\n",
    "         erase_cropped: bool = True) -> tuple[Image.Image, tuple[list[int], list[Box]]]:\n",
    "    \"\"\"Crops an image and adjusts annotations based oWSn the crop region.\n",
    "\n",
    "    Args:\n",
    "        cropped_img: The PIL Image object to crop\n",
    "        crop_box: The bounding box defining the crop region in XYXY format\n",
    "        annots: A dictionary containing \"category_id\" and \"boxes\" lists representing annotations\n",
    "        crop_tolerance: The tolerance for considering an annotation as fully within the crop\n",
    "        erase_cropped: Whether to draw over partially cropped annotations on the image\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing the cropped image and the adjusted annotations\n",
    "    \"\"\"\n",
    "\n",
    "    cropped_annots = {\"category_id\": [], \"boxes\": []}\n",
    "    labels, bboxes = annots[\"category_id\"], annots[\"boxes\"]\n",
    "    \n",
    "    draw_context = ImageDraw.Draw(cropped_img)\n",
    "    for label, bbox in zip(labels, bboxes):\n",
    "        relative_bbox = (max(crop_box[0], bbox[0]) - crop_box[0], #xmin\n",
    "                         max(crop_box[1], bbox[1]) - crop_box[1], #ymin\n",
    "                         min(crop_box[2], bbox[2]) - crop_box[0], #xmax\n",
    "                         min(crop_box[3], bbox[3]) - crop_box[1]) #ymax\n",
    "        cropped = 1 - box_area(relative_bbox) / box_area(bbox)\n",
    "        if cropped <= crop_tolerance:\n",
    "            cropped_annots[\"category_id\"].append(label)\n",
    "            cropped_annots[\"boxes\"].append(relative_bbox)\n",
    "        elif cropped < 1 and erase_cropped:\n",
    "            draw_context.rectangle(relative_bbox, width=1, fill=\"purple\")\n",
    "\n",
    "    return cropped_annots\n",
    "\n",
    "def patch_sample(img: Image.Image,\n",
    "                 annots: dict[str, Any],\n",
    "                 desired_image_size: int,\n",
    "                 overlap: float,\n",
    "                 crop_tolerance: float) -> tuple[list[Image.Image], list[tuple[list[int], list[Box]]]]:\n",
    "    \"\"\"Patches a large image into smaller images with adjusted annotations.\n",
    "    Args:\n",
    "        img: The PIL Image object to patch\n",
    "        annots: A tuple containing category_id and boxes lists representing annotations\n",
    "        desired_image_size: The desired size of each patch\n",
    "        overlap: The overlap between adjacent patches (as a fraction of `desired_image_size`)\n",
    "        crop_tolerance: The tolerance for considering an annotation as fully within a patch\n",
    "    Returns:\n",
    "        A tuple containing a list of patched images and a list of corresponding adjusted annotations\n",
    "    \"\"\"\n",
    "    \n",
    "    padded_width, padded_height, patch_boxes = make_patches(img.width, img.height, desired_image_size, overlap)\n",
    "    padded_img = Image.new(\"RGB\", (padded_width, padded_height))\n",
    "    padded_img.paste(img)\n",
    "    res_imgs, res_annots = [], []\n",
    "    \n",
    "    for patch_box in patch_boxes:\n",
    "        patched_img = padded_img.crop(patch_box)\n",
    "        patched_annots = patch_annots(patched_img, patch_box, annots, crop_tolerance)\n",
    "        if patched_annots[\"category_id\"]:\n",
    "            res_imgs.append(patched_img)\n",
    "            res_annots.append(patched_annots)\n",
    "\n",
    "    return res_imgs, res_annots\n",
    "\n",
    "def patch_dataset(dataset_root: str,\n",
    "                  desired_image_size: int = 1024,\n",
    "                  overlap: float = 0.2,\n",
    "                  crop_tolerance: float=0.3):\n",
    "    \"\"\"Patches images in a dataset and saves the patched images and annotations.\n",
    "\n",
    "    Args:\n",
    "        dataset_root: The root directory of the dataset\n",
    "        desired_image_size: The desired size of each patch\n",
    "        overlap: The overlap between adjacent patches (as a fraction of `desired_image_size`)\n",
    "        crop_tolerance: The tolerance for considering an annotation as fully within a patch\n",
    "    \"\"\"\n",
    "    dataset_root = os.path.normpath(dataset_root)\n",
    "    annot_file = os.path.join(dataset_root, \"dataset.json\")\n",
    "    imgs_dir = os.path.join(dataset_root, \"imgs\")\n",
    "    dataset_parent = os.path.dirname(dataset_root)\n",
    "    patched_root = os.path.join(dataset_parent, os.path.basename(dataset_root) + \"_patched_croptolerance=\" + str(crop_tolerance))\n",
    "    os.makedirs(os.path.join(patched_root, \"imgs\"), exist_ok=True)\n",
    "    \n",
    "    patched_dataset = {}\n",
    "    \n",
    "    with open(annot_file, 'r') as annot_file:\n",
    "        dataset = json.load(annot_file)\n",
    "        \n",
    "    for image_id, annotations in dataset.items():\n",
    "        \n",
    "        img = Image.open(os.path.join(imgs_dir, f\"{image_id}.jpeg\"))\n",
    "        patched_imgs, patched_annots = patch_sample(img, annotations, desired_image_size, overlap, crop_tolerance)\n",
    "        patch_num = 1\n",
    "        \n",
    "        for patched_image, patched_annotations in zip(patched_imgs, patched_annots):\n",
    "            patch_id = f\"{image_id}_{patch_num}\"\n",
    "            patched_dataset[patch_id] = patched_annotations\n",
    "            patched_image.save(os.path.join(patched_root, \"imgs\", patch_id + \".jpeg\"), quality=100)\n",
    "            patch_num += 1\n",
    "            \n",
    "    with open(os.path.join(patched_root, \"dataset.json\"), \"w\") as outfile: \n",
    "        json.dump(patched_dataset, outfile, indent=1)\n",
    "        \n",
    "patch_dataset(OUTPUT_DATASET, crop_tolerance=0.5) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".wslvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
