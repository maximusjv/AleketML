{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKXbvPtmIAzW"
   },
   "source": [
    "# TODO - describe this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10801,
     "status": "ok",
     "timestamp": 1726688877827,
     "user": {
      "displayName": "maximus JV",
      "userId": "01037924598235015782"
     },
     "user_tz": -180
    },
    "id": "oLaoTSNaIAzX"
   },
   "outputs": [],
   "source": [
    "%pip install pillow\n",
    "%pip install numpy<2.0\n",
    "%pip install torch torchvision --index-url https://download.pytorch.org/whl/cu124\n",
    "%pip install matplotlib\n",
    "%pip install pycocotools\n",
    "%pip install gdown\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "clear_output(wait=False)\n",
    "\n",
    "print(\"ALL DEPENDENCIES INSTALLED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 7480,
     "status": "ok",
     "timestamp": 1726688885304,
     "user": {
      "displayName": "maximus JV",
      "userId": "01037924598235015782"
     },
     "user_tz": -180
    },
    "id": "QYh3of1UgFZs"
   },
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import copy\n",
    "import io\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "from contextlib import redirect_stdout\n",
    "from typing import Optional, Any\n",
    "\n",
    "# Third-Party Libraries\n",
    "import gdown\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "\n",
    "#Torch\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "\n",
    "# Torchvision\n",
    "import torchvision.models.detection as tv_detection\n",
    "import torchvision.transforms.v2 as v2\n",
    "import torchvision.tv_tensors as tv_tensors\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1726688885305,
     "user": {
      "displayName": "maximus JV",
      "userId": "01037924598235015782"
     },
     "user_tz": -180
    },
    "id": "GnNZd4yVIAzX"
   },
   "outputs": [],
   "source": [
    "# DATASET UTILS\n",
    "def load_annotations(file: str) -> dict[str, Any]:\n",
    "    with open(file, 'r') as annot_file:\n",
    "        dataset = json.load(annot_file)\n",
    "    return dataset\n",
    "\n",
    "class AleketDataset(Dataset):\n",
    "\n",
    "    NUM_TO_CLASSES = {'placeholder': 0, 'healthy': 1, 'nec': 2}\n",
    "    CLASSES_TO_NUM = {0: 'placeholder', 1: 'healthy', 2: 'nec'}\n",
    "\n",
    "    def __init__(self,\n",
    "                 dataset_dir: str,\n",
    "                 transforms: Optional[nn.Module] = None) -> None:\n",
    "        self.img_dir = f\"{dataset_dir}/imgs\"\n",
    "        self.dataset = load_annotations(f\"{dataset_dir}/dataset.json\")\n",
    "\n",
    "        self.default_transforms = v2.Compose([v2.ToDtype(torch.float32, scale=True)])\n",
    "        self.train = True\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset[\"imgs\"])\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        img_path = f\"{self.img_dir}/{self.dataset['imgs'][idx]}.jpeg\"\n",
    "        img = PIL.Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        annots = self.dataset[\"annotations\"][idx]\n",
    "        labels, bboxes = annots[\"category_id\"], annots[\"boxes\"]\n",
    "\n",
    "        img = tv_tensors.Image(img, dtype=torch.uint8)\n",
    "\n",
    "        img = img[:3, :, :]\n",
    "\n",
    "        wt = img.shape[-1]\n",
    "        ht = img.shape[-2]\n",
    "\n",
    "        labels = torch.as_tensor(labels)\n",
    "        bboxes = tv_tensors.BoundingBoxes(bboxes, format=\"XYXY\", canvas_size=(wt, ht))\n",
    "\n",
    "        if self.train and self.transforms is not None:\n",
    "            img, bboxes, labels = self.transforms(img, bboxes, labels)\n",
    "            \n",
    "        area = (bboxes[:, 3] - bboxes[:, 1]) * (bboxes[:, 2] - bboxes[:, 0])\n",
    "        iscrowd = torch.zeros((bboxes.shape[0],), dtype=torch.int64)\n",
    "\n",
    "        img, bboxes, labels = self.default_transforms(img, bboxes, labels)\n",
    "        target = {\"boxes\": bboxes, \"labels\": labels, \"area\": area, \"image_id\": idx, \"iscrowd\": iscrowd}\n",
    "\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1726688885305,
     "user": {
      "displayName": "maximus JV",
      "userId": "01037924598235015782"
     },
     "user_tz": -180
    },
    "id": "BkzLDNwPIAzY"
   },
   "outputs": [],
   "source": [
    "# COCO METRICS UTILS\n",
    "\n",
    "def convert_to_coco_api(dataset: Dataset):\n",
    "\n",
    "    ds = {\"images\": [], \"categories\": [], \"annotations\": []}\n",
    "    categories = set()\n",
    "    ann_id = 1\n",
    "\n",
    "    for idx in range(len(dataset)):\n",
    "        img, targets = dataset[idx]\n",
    "        img_id = targets[\"image_id\"]\n",
    "\n",
    "        img_entry = {}\n",
    "        img_entry[\"id\"] = img_id\n",
    "        img_entry[\"height\"] = img.shape[-2]\n",
    "        img_entry[\"width\"] = img.shape[-1]\n",
    "\n",
    "        ds[\"images\"].append(img_entry)\n",
    "\n",
    "        bboxes = targets[\"boxes\"].clone()\n",
    "        bboxes[:, 2:] -= bboxes[:, :2]  # xyxy to xywh (coco format)\n",
    "\n",
    "        bboxes = bboxes.tolist()\n",
    "        labels = targets[\"labels\"].tolist()\n",
    "        areas = targets[\"area\"].tolist()\n",
    "        iscrowd = targets[\"iscrowd\"].tolist()\n",
    "\n",
    "        num_objs = len(bboxes)\n",
    "\n",
    "        for i in range(num_objs):\n",
    "            ann = {\"image_id\": img_id, \"bbox\": bboxes[i],\n",
    "                   \"category_id\": labels[i], \"area\": areas[i],\n",
    "                   \"iscrowd\": iscrowd[i], \"id\": ann_id}\n",
    "            categories.add(labels[i])\n",
    "            ds[\"annotations\"].append(ann)\n",
    "            ann_id += 1\n",
    "\n",
    "    ds[\"categories\"] = [{\"id\": i} for i in sorted(categories)]  # TODO add names\n",
    "\n",
    "    with redirect_stdout(io.StringIO()):\n",
    "        coco_ds = COCO()\n",
    "        coco_ds.dataset = ds\n",
    "        coco_ds.createIndex()\n",
    "    return coco_ds\n",
    "\n",
    "\n",
    "def stats_dict(stats: np.ndarray):\n",
    "    #  According to https://cocodataset.org/#detection-eval\n",
    "    return {\n",
    "        \"AP\": stats[0],\n",
    "        \"AP@0.5\": stats[1],\n",
    "        \"AP@0.75\": stats[2],\n",
    "        \"AP small\": stats[3],\n",
    "        \"AP medium\": stats[4],\n",
    "        \"AP large\": stats[5],\n",
    "        \"AR max=1\": stats[6],\n",
    "        \"AR max=10\": stats[7],\n",
    "        \"AR max=100\": stats[8],\n",
    "        \"AR small\":stats[9],\n",
    "        \"AR medium\":stats[10],\n",
    "        \"AR large\":stats[11]\n",
    "    }\n",
    "\n",
    "\n",
    "class CocoEvaluator:\n",
    "    def __init__(self, gt_dataset):\n",
    "        if isinstance(gt_dataset, Dataset):\n",
    "            gt_dataset = convert_to_coco_api(gt_dataset)\n",
    "\n",
    "        self.coco_gt = copy.deepcopy(gt_dataset)\n",
    "        self.coco_dt = []\n",
    "\n",
    "        self.img_ids = set()\n",
    "\n",
    "    def append(self, predictions):\n",
    "        for image_id, prediction in predictions.items():\n",
    "            if len(prediction) == 0:\n",
    "                continue\n",
    "            if image_id in self.img_ids:\n",
    "                raise Exception(f\"image with an id: {image_id} is already got predicted, ids must be unique\")\n",
    "            self.img_ids.add(image_id)\n",
    "\n",
    "            boxes = prediction[\"boxes\"].clone()\n",
    "            boxes[:, 2:] -= boxes[:, :2]\n",
    "            boxes = boxes.tolist()\n",
    "            scores = prediction[\"scores\"].tolist()\n",
    "            labels = prediction[\"labels\"].tolist()\n",
    "\n",
    "            self.coco_dt.extend([\n",
    "                {\n",
    "                    \"image_id\": image_id,\n",
    "                    \"category_id\": labels[k],\n",
    "                    \"bbox\": box,\n",
    "                    \"score\": scores[k],\n",
    "                }\n",
    "                for k, box in enumerate(boxes)\n",
    "            ]\n",
    "            )\n",
    "\n",
    "    def eval(self):\n",
    "        if not self.coco_dt:\n",
    "            print(\"NO PREDICTIONS\")\n",
    "            return stats_dict(np.zeros(12))\n",
    "        with redirect_stdout(io.StringIO()):\n",
    "            coco_dt = COCO.loadRes(self.coco_gt, self.coco_dt)  # type: ignore\n",
    "            coco = COCOeval(self.coco_gt, coco_dt, iouType=\"bbox\")\n",
    "            coco.evaluate()\n",
    "            coco.accumulate()\n",
    "        coco.summarize()\n",
    "        return stats_dict(coco.stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1726688885305,
     "user": {
      "displayName": "maximus JV",
      "userId": "01037924598235015782"
     },
     "user_tz": -180
    },
    "id": "FOaYqVhrIAzY"
   },
   "outputs": [],
   "source": [
    "# TRAIN AND EVAL UTILS\n",
    "def log_metric(\n",
    "    batch: int,\n",
    "    total_batches: int,\n",
    "    time_passed: Optional[float] = None,\n",
    "    losses_dict: Optional[dict] = None,\n",
    "    total_loss: Optional[float] = None,\n",
    "):\n",
    "\n",
    "    td = f\" time: {time_passed}\" if time_passed is not None else \"\"\n",
    "    loss_msg = f\"Loss: {total_loss} \" if total_loss is not None else \"\"\n",
    "    loss_dict = (\n",
    "        f'loss_classifier: {losses_dict[\"loss_classifier\"]} loss_box_reg: {losses_dict[\"loss_box_reg\"]} loss_objectness: {losses_dict[\"loss_objectness\"]} loss_rpn_box_reg: {losses_dict[\"loss_rpn_box_reg\"]}'\n",
    "        if losses_dict is not None\n",
    "        else \"\"\n",
    "    )\n",
    "\n",
    "    print(f\"[{batch}/{total_batches}] \" + loss_msg + loss_dict + td)\n",
    "\n",
    "\n",
    "def filter_predictions_by_conf(predictions: list, conf_thresh: float):\n",
    "    filtered_predictions = []\n",
    "    for prediction in predictions:\n",
    "        boxes = prediction[\"boxes\"]\n",
    "        labels = prediction[\"labels\"]\n",
    "        scores = prediction[\"scores\"]\n",
    "\n",
    "        keep_indices = torch.where(scores > conf_thresh)[0]\n",
    "\n",
    "        filtered_boxes = boxes[keep_indices]\n",
    "        filtered_labels = labels[keep_indices]\n",
    "        filtered_scores = scores[keep_indices]\n",
    "\n",
    "        filtered_prediction = {\n",
    "            \"boxes\": filtered_boxes,\n",
    "            \"labels\": filtered_labels,\n",
    "            \"scores\": filtered_scores,\n",
    "        }\n",
    "        filtered_predictions.append(filtered_prediction)\n",
    "    return filtered_predictions\n",
    "\n",
    "\n",
    "def train_one_epoch(\n",
    "    model: tv_detection.FasterRCNN,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    dataloader: DataLoader,\n",
    "    device: str,\n",
    "    epoch: int,\n",
    "    printFreq: int = 1,\n",
    ") -> float:\n",
    "    model.train()\n",
    "    size = len(dataloader)\n",
    "    loss_values = torch.zeros(size, dtype=torch.float32)\n",
    "    t = time.time()\n",
    "\n",
    "    for batch_num, (imgs, targets) in enumerate(dataloader):\n",
    "        imgs = [img.to(device) for img in imgs]\n",
    "        targets = [\n",
    "            {\n",
    "                k: v.to(device) if isinstance(v, torch.Tensor) else v\n",
    "                for k, v in t.items()\n",
    "            }\n",
    "            for t in targets\n",
    "        ]  # {bboxes: ..., labels:... }\n",
    "\n",
    "        losses = model(imgs, targets)\n",
    "        loss = sum(loss for loss in losses.values())\n",
    "        loss_values[batch_num] = loss.item()\n",
    "        if not math.isfinite(loss):\n",
    "            print(f\"Loss is {loss.item()}, stopping training\")\n",
    "            print(losses)\n",
    "            sys.exit(1)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if printFreq != 0 and batch_num % printFreq == 0:\n",
    "            t = time.time() - t\n",
    "            log_metric(\n",
    "                batch_num,\n",
    "                size,\n",
    "                time_passed=t,\n",
    "                losses_dict=losses,\n",
    "                total_loss=loss.item(),\n",
    "            )\n",
    "            t = time.time()\n",
    "\n",
    "    epoch_loss = loss_values.mean().item()\n",
    "\n",
    "    print(f\"Epoch {epoch} loss: {epoch_loss}\")\n",
    "    return epoch_loss\n",
    "\n",
    "\n",
    "def evaluate(\n",
    "    model: tv_detection.FasterRCNN,\n",
    "    dataloader: DataLoader,\n",
    "    device: str,\n",
    "    conf_thresh: float = 0.1,\n",
    "    printFreq: int = 1,\n",
    ") -> Any:\n",
    "\n",
    "    size = len(dataloader)\n",
    "    model.eval()\n",
    "\n",
    "    t = time.time()\n",
    "    coco_eval = CocoEvaluator(dataloader.dataset)\n",
    "\n",
    "    for batch_num, (imgs, targets) in enumerate(dataloader):\n",
    "\n",
    "        imgs = [img.to(device) for img in imgs]\n",
    "        targets = [\n",
    "            {\n",
    "                k: v.to(device) if isinstance(v, torch.Tensor) else v\n",
    "                for k, v in t.items()\n",
    "            }\n",
    "            for t in targets\n",
    "        ]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predictions = model(imgs)\n",
    "            predictions = filter_predictions_by_conf(predictions, conf_thresh)\n",
    "            res = {\n",
    "                target[\"image_id\"]: output\n",
    "                for target, output in zip(targets, predictions)\n",
    "            }\n",
    "            coco_eval.append(res)\n",
    "\n",
    "        if printFreq != 0 and batch_num % printFreq == 0:\n",
    "            t = time.time() - t\n",
    "            log_metric(batch_num, size, time_passed=t)\n",
    "            t = time.time()\n",
    "\n",
    "    stats = coco_eval.eval()\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH VARIABLES\n",
    "def get_dataset(save_dir: str):\n",
    "    patched_dataset_gdrive_id = \"\"  # FIXME\n",
    "    if not os.path.exists(save_dir):\n",
    "        gdown.download(id=patched_dataset_gdrive_id, output=\"_temp_.zip\")\n",
    "        shutil.unpack_archive(\"_temp_.zip\", save_dir)\n",
    "        os.remove(\"_temp_.zip\")\n",
    "    print(f\"DATASET {save_dir} LOADED\")\n",
    "    return save_dir\n",
    "\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"USING {DEVICE}\")\n",
    "DATASET_ROOT = get_dataset(\"dataset_patched/\")\n",
    "MODEL_DIR = \"result/\"\n",
    "LAST_MODEL_PATH = f\"{MODEL_DIR}/last_model.pth\"\n",
    "BEST_MODEL_PATH = f\"{MODEL_DIR}/best_model.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN SETTINGS\n",
    "SEED = 1\n",
    "\n",
    "LOAD_BEST = False\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 500\n",
    "TEST_FRACTION = 0.2\n",
    "DATASET_FRACTION = 1\n",
    "DATALOADER_WORKERS = 8\n",
    "LR = 0.001\n",
    "\n",
    "TRANSFORMS = v2.Compose(\n",
    "    [\n",
    "        v2.RandomHorizontalFlip(0.5),\n",
    "        v2.RandomVerticalFlip(0.5),\n",
    "        v2.RandomPerspective(0.1, p=0.1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def get_model(num_classes) -> tv_detection.FasterRCNN:\n",
    "    if LOAD_BEST and os.path.exists(BEST_MODEL_PATH):\n",
    "        model = torch.load(BEST_MODEL_PATH, weights_only=False)\n",
    "    else:\n",
    "        model = tv_detection.fasterrcnn_resnet50_fpn_v2(\n",
    "            weights=\"DEFAULT\"\n",
    "        )\n",
    "        in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "        model.roi_heads.box_predictor = (\n",
    "            tv_detection.faster_rcnn.FastRCNNPredictor(\n",
    "                in_features, num_classes\n",
    "            )\n",
    "        )\n",
    "    return model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G9UdbXiJIAzZ",
    "outputId": "4eaac050-8192-4ffe-e5ae-ee59701ce7b2"
   },
   "outputs": [],
   "source": [
    "# main\n",
    "def set_seed():\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    pass\n",
    "\n",
    "\n",
    "def save_model(model, is_best):\n",
    "    os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "    torch.save(model, LAST_MODEL_PATH)\n",
    "    if is_best:\n",
    "        torch.save(model, BEST_MODEL_PATH)\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    set_seed()\n",
    "    model = get_model(3)\n",
    "\n",
    "    dataset = AleketDataset(DATASET_ROOT, transforms=TRANSFORMS)\n",
    "\n",
    "    size = int(len(dataset) * DATASET_FRACTION)\n",
    "    indices = torch.randperm(size).tolist()\n",
    "\n",
    "    test_size = int(size * TEST_FRACTION)\n",
    "    train_dataset = Subset(dataset, indices[:-test_size])\n",
    "    val_dataset = Subset(dataset, indices[-test_size:])\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        collate_fn=collate_fn,\n",
    "        num_workers=DATALOADER_WORKERS,\n",
    "    )\n",
    "\n",
    "    val_dataloader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        collate_fn=collate_fn,\n",
    "        num_workers=DATALOADER_WORKERS,\n",
    "    )\n",
    "\n",
    "    optimizer = optim.AdamW(params=model.parameters(), lr=LR)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "        optimizer, start_factor=1, end_factor=0.1, total_iters=15\n",
    "    )\n",
    "    best_ap = -1\n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"Epoch: {epoch}/{EPOCHS}\\tLearning rate: {lr_scheduler.get_last_lr()}\")\n",
    "        dataset.train = True\n",
    "        train_one_epoch(model, optimizer, train_dataloader, DEVICE, epoch, printFreq=20)\n",
    "\n",
    "        print(f\"Evaluating: \")\n",
    "        dataset.train = False\n",
    "        eval_stats = evaluate(\n",
    "            model, val_dataloader, DEVICE, conf_thresh=0, printFreq=100\n",
    "        )\n",
    "        ap = eval_stats[\"AP\"]\n",
    "        save_model(model, ap > best_ap)\n",
    "        best_ap = max(best_ap, ap)\n",
    "        print(f\"AP: {ap}\")\n",
    "        lr_scheduler.step()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "https://github.com/maximusjv/AleketML/blob/main/aleket.ipynb",
     "timestamp": 1726685419266
    }
   ]
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
