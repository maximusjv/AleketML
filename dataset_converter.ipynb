{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO - DESCRIBE THIS FILE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Pillow if not already installed\n",
    "# %pip install pillow  # This line is likely for a Jupyter Notebook environment\n",
    "\n",
    "# Standard Library\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import shutil\n",
    "from typing import Any, NewType\n",
    "import csv \n",
    "\n",
    "# Third-Party Libraries\n",
    "from PIL import Image, ImageDraw\n",
    "from PIL.TiffTags import TAGS\n",
    "\n",
    "# Type Alias for Bounding Boxes\n",
    "Box = NewType('Box', tuple[int, int, int, int])\n",
    "\n",
    "# Dataset Paths (Remember to replace placeholders with your actual paths)\n",
    "DATASET_SOURCE = \"/mnt/f/dataUtils/raw_data\"  # FIXME: Change accordingly\n",
    "OUTPUT_DATASET = \"/mnt/e/dataset\"  # FIXME: Change accordingly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Math utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils\n",
    "def get_image_metadata(img: Image) -> dict[str, float]:\n",
    "    \"\"\"Extracts resolution metadata from a TIFF image.\n",
    "    Args:\n",
    "        img: A PIL Image object.\n",
    "    Returns:\n",
    "        A dictionary containing resolution information (x, y, and unit).\n",
    "    \"\"\"\n",
    "    tiff_tags = {TAGS.get(tag, tag): value for tag, value in img.tag.items()}\n",
    "        \n",
    "    res = {\n",
    "        \"x_resolution\": tiff_tags['XResolution'][0][0]/tiff_tags['XResolution'][0][1],\n",
    "        \"y_resolution\": tiff_tags['YResolution'][0][0]/tiff_tags['YResolution'][0][1],\n",
    "        \"resolution_unit\": tiff_tags['ResolutionUnit'] \n",
    "    }\n",
    "    return res\n",
    "\n",
    "class ImageUtils:\n",
    "    \"\"\"Provides utility functions for working with image resolutions and areas.\"\"\"\n",
    "\n",
    "    def __init__(self, img):\n",
    "        self.img = img\n",
    "        self.metadata = get_image_metadata(img)\n",
    "        self.x_resolution = float(self.metadata[\"x_resolution\"])\n",
    "        self.y_resolution = float(self.metadata[\"y_resolution\"])\n",
    "\n",
    "    def area_units_to_pixels(self, area):\n",
    "        \"\"\"Converts area from resolution units to pixels.\"\"\"\n",
    "        return float(area) * (max(self.x_resolution, self.y_resolution) ** 2)\n",
    "\n",
    "    def area_pixels_to_units(self, area):\n",
    "        \"\"\"Converts area from pixels to resolution units.\"\"\"\n",
    "        return float(area) / (max(self.x_resolution, self.y_resolution) ** 2)\n",
    "\n",
    "\n",
    "class ImageUtilOpener:\n",
    "    \"\"\"Context manager for opening and working with an image.\"\"\"\n",
    "\n",
    "    def __init__(self, file_name):\n",
    "        self.file_name = file_name\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.img = Image.open(self.file_name)\n",
    "        return ImageUtils(self.img)\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        self.img.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read csv+tif ImageJ-created dataset, and convert to dict\n",
    "of images_path as keys and corresponding bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_cxcywh_to_xyxy(box: Box) -> Box:\n",
    "    \"\"\"Converts a bounding box from center-x, center-y, width, height format (CXCYWH) \n",
    "    to top-left-x, top-left-y, bottom-right-x, bottom-right-y format (XYXY).\n",
    "    Args:\n",
    "        box: A tuple representing the bounding box in CXCYWH format.\n",
    "    Returns:\n",
    "        A tuple representing the bounding box in XYXY format.\n",
    "    \"\"\"\n",
    "    cx, cy, w, h = box\n",
    "    xmin = cx-w//2\n",
    "    ymin = cy-h//2\n",
    "    xmax = cx+(w+1)//2  # ceil\n",
    "    ymax = cy+(h+1)//2  # ceil\n",
    "    return xmin, ymin, xmax, ymax\n",
    "\n",
    "\n",
    "def sanitize_annotations(name:str, annotation: dict[str, Any]) -> None:\n",
    "    \"\"\"Sanitizes annotations by removing duplicates and invalid bounding boxes.\n",
    "\n",
    "    Args:\n",
    "        name: The name of the image associated with the annotations.\n",
    "        annotations: A dictionary containing \"category_id\" and \"boxes\" lists.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing sanitized \"category_id\" and \"boxes\" lists.\n",
    "    \"\"\"\n",
    "    sanitized_annotations = {\n",
    "        \"category_id\": [],\n",
    "        \"boxes\": []\n",
    "    }\n",
    "    \n",
    "    bbox_dict = dict()\n",
    "    for label, bbox in zip(annotation[\"category_id\"], annotation[\"boxes\"]):\n",
    "        if bbox in bbox_dict:\n",
    "            if bbox_dict[bbox] == label:\n",
    "                print(f\"WARNING: Duplicate bbox found in {name}: {bbox}\")\n",
    "            else:\n",
    "                print(f\"ERROR: Same bbox with different label found in {name}: {bbox}\")\n",
    "            continue\n",
    "        if any(coord < 0 for coord in bbox):\n",
    "            print(f\"Corrupted box found in {name}: {bbox}\")\n",
    "            continue\n",
    "\n",
    "        bbox_dict[bbox] = label\n",
    "\n",
    "    for key in bbox_dict:\n",
    "        sanitized_annotations[\"category_id\"].append(bbox_dict[key])\n",
    "        sanitized_annotations[\"boxes\"].append(key)\n",
    "\n",
    "    return sanitized_annotations\n",
    "        \n",
    "def convert_annotations(csv_path: str, img_path: str) -> dict[str, Any]:\n",
    "    \"\"\"Converts a CSV file and an image into annotations.\n",
    "    Args:\n",
    "        csv_path: The path to the CSV file containing annotations.\n",
    "        img_path: The path to the image file.\n",
    "    Returns:\n",
    "        A dictionary containing \"category_id\" and \"boxes\" lists representing the annotations.\n",
    "    \"\"\"\n",
    "    annotations = {}\n",
    "    name = os.path.basename(img_path).removesuffix(\".tif\")\n",
    "    annotations = {\n",
    "        \"category_id\": [],\n",
    "        \"boxes\": []\n",
    "    }\n",
    "    \n",
    "    with ImageUtilOpener(img_path) as util:\n",
    "        if os.path.exists(csv_path): \n",
    "            with open(csv_path) as data_file:\n",
    "                data = csv.reader(data_file)\n",
    "                next(data) # Skip header row\n",
    "                for row in data:\n",
    "                    try:\n",
    "                        _, label, area, category_id, _ = row  # Unpack row, ignore filename and category_name\n",
    "                        _, (y, x) = label.split(':')  # Extract coordinates from label\n",
    "                        y, x = int(y), int(x)\n",
    "\n",
    "                        area_in_pixels = util.area_units_to_pixels(float(area))\n",
    "                        bbox_side = int(math.sqrt(area_in_pixels / math.pi) * 2)  # Calculate square side length\n",
    "\n",
    "                        bbox = convert_cxcywh_to_xyxy((x, y, bbox_side, bbox_side))\n",
    "                        annotations[\"category_id\"].append(int(category_id))\n",
    "                        annotations[\"boxes\"].append(bbox)\n",
    "                    except Exception as e:\n",
    "                        annotations[\"boxes\"] = []\n",
    "                        annotations[\"category_id\"] = []\n",
    "                        print(f\"Error processing row in {csv_path}: {e}\")\n",
    "                        print(f\"{csv_path} Failed\")\n",
    "                        break  \n",
    "                     \n",
    "    return annotations\n",
    "    \n",
    "    \n",
    "def convert_dataset(data_path: str, imgs_path: str, res_path: str, replace_imgs=True):\n",
    "    \"\"\"Converts a dataset from the source format to the desired output format.\n",
    "    Args:\n",
    "        data_path: The path to the directory containing CSV annotation files\n",
    "        imgs_path: The path to the directory containing image files\n",
    "        res_path: The path to the output directory where the converted dataset will be saved\n",
    "        replace_imgs: Whether to replace existing images in the output directory\n",
    "    \"\"\"\n",
    "    img_list = [\n",
    "        os.path.splitext(f)[0] \n",
    "        for f in os.listdir(imgs_path) \n",
    "        if os.path.isfile(os.path.join(imgs_path, f)) and f.endswith(\".tif\")\n",
    "    ]\n",
    "    \n",
    "    if replace_imgs:\n",
    "        try:\n",
    "            shutil.rmtree(res_path)\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "\n",
    "    os.makedirs(os.path.join(res_path, \"imgs\"), exist_ok=True)\n",
    "       \n",
    "    dataset = {\n",
    "        \"imgs\": [],\n",
    "        \"annotations\": []\n",
    "    }\n",
    "    img_id = 1  # Start image IDs from 1\n",
    "    \n",
    "    for name in img_list:\n",
    "        csv_path = f'{data_path}/{name}.tif.csv'\n",
    "        img_path = f'{imgs_path}/{name}.tif'\n",
    "        annotations = convert_annotations(csv_path, img_path)\n",
    "        if not annotations[\"boxes\"]:\n",
    "            continue # Skip images without annotations\n",
    "\n",
    "        if replace_imgs:\n",
    "            img = Image.open(img_path)\n",
    "            img.save(os.path.join(res_path, \"imgs\", f\"{img_id}.jpeg\"), quality=100)\n",
    "        \n",
    "        annotations = sanitize_annotations(name, annotations)\n",
    "        dataset[\"imgs\"].append(f\"{img_id}\")\n",
    "        dataset[\"annotations\"].append(annotations)\n",
    "        img_id += 1\n",
    "\n",
    "    with open(os.path.join(res_path, \"dataset.json\"), \"w\") as outfile:\n",
    "        json.dump(dataset, outfile, indent=4)\n",
    "    print(\"Finished converting\")\n",
    "    \n",
    "convert_dataset(f\"{DATASET_SOURCE}/csv\", f\"{DATASET_SOURCE}/imgs\", OUTPUT_DATASET, replace_imgs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Patch dataset into images of desired size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cropped_coefficient(src_box: Box, cover_box: Box) -> float:\n",
    "    \"\"\"Calculates the cover coefficient between two bounding boxes.\n",
    "\n",
    "    The cover coefficient measures how much of the `src_box` is covered by the `cover_box`.\n",
    "    It is calculated as the intersection area between the two boxes divided by the area of the `src_box`.\n",
    "\n",
    "    Args:\n",
    "        src_box: The source bounding box in XYXY format.\n",
    "        cover_box: The covering bounding box in XYXY format.\n",
    "\n",
    "    Returns:\n",
    "        The cover coefficient between the two boxes (a value between 0 and 1).\n",
    "    \"\"\"\n",
    "    xmin1, ymin1, xmax1, ymax1 = src_box\n",
    "    xmin2, ymin2, xmax2, ymax2 = cover_box\n",
    "    inter_xmin = max(xmin1, xmin2)\n",
    "    inter_ymin = max(ymin1, ymin2)\n",
    "    inter_xmax = min(xmax1, xmax2)\n",
    "    inter_ymax = min(ymax1, ymax2)\n",
    "    \n",
    "    intersection_area = max(0, inter_xmax - inter_xmin) * max(0, inter_ymax - inter_ymin)\n",
    "    src_box_area = max(0, xmax1 - xmin1) * max(0, ymax1 - ymin1)\n",
    "    if src_box_area == 0:\n",
    "        return -1\n",
    "    \n",
    "    return 1 - intersection_area / src_box_area\n",
    "    \n",
    "\n",
    "def crop(img: Image.Image,\n",
    "         crop_box: Box,\n",
    "         annots: tuple[list[int], list[Box]],\n",
    "         crop_tolerance: float,\n",
    "         crop_not_tolerated: bool = True) -> tuple[Image.Image, tuple[list[int], list[Box]]]:\n",
    "    \"\"\"Crops an image and adjusts annotations based on the crop region.\n",
    "\n",
    "    Args:\n",
    "        img: The PIL Image object to crop\n",
    "        crop_box: The bounding box defining the crop region in XYXY format\n",
    "        annots: A dictionary containing \"category_id\" and \"boxes\" lists representing annotations\n",
    "        crop_tolerance: The tolerance for considering an annotation as fully within the crop\n",
    "        crop_not_tolerated: Whether to draw over partially cropped annotations on the image\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing the cropped image and the adjusted annotations\n",
    "    \"\"\"\n",
    "    cropped_img = img.crop(crop_box)\n",
    "    cropped_annots = {\"category_id\": [], \"boxes\": []}\n",
    "    labels, bboxes = annots[\"category_id\"], annots[\"boxes\"]\n",
    "    \n",
    "    draw_context = ImageDraw.Draw(cropped_img)\n",
    "    for label, bbox in zip(labels, bboxes):\n",
    "        relative_bbox = (max(crop_box[0], bbox[0]) - crop_box[0],\n",
    "                         max(crop_box[1], bbox[1]) - crop_box[1],\n",
    "                         min(crop_box[2], bbox[2]) - crop_box[0],\n",
    "                         min(crop_box[3], bbox[3]) - crop_box[1])\n",
    "        cropped = calculate_cropped_coefficient(crop_box, bbox)\n",
    "        if cropped <= crop_tolerance:\n",
    "            cropped_annots[\"category_id\"].append(label)\n",
    "            cropped_annots[\"boxes\"].append(relative_bbox)\n",
    "        elif cropped > 0 and crop_not_tolerated:\n",
    "            draw_context.rectangle(relative_bbox, width=1, fill=\"purple\")\n",
    "\n",
    "    return cropped_img, cropped_annots\n",
    "\n",
    "def patch_img(img: Image.Image,\n",
    "          annots: dict[str, Any],\n",
    "          desired_image_size: int,\n",
    "          overlap: float,\n",
    "          crop_tolerance: float) -> tuple[list[Image.Image], list[tuple[list[int], list[Box]]]]:\n",
    "    \"\"\"Patches a large image into smaller images with adjusted annotations.\n",
    "\n",
    "    Args:\n",
    "        img: The PIL Image object to patch\n",
    "        annots: A tuple containing category_id and boxes lists representing annotations\n",
    "        desired_image_size: The desired size of each patch\n",
    "        overlap: The overlap between adjacent patches (as a fraction of `desired_image_size`)\n",
    "        crop_tolerance: The tolerance for considering an annotation as fully within a patch\n",
    "    Returns:\n",
    "        A tuple containing a list of patched images and a list of corresponding adjusted annotations\n",
    "    \"\"\"\n",
    "    \n",
    "    overlap_size = int(desired_image_size * overlap)\n",
    "    no_overlap_size = desired_image_size - overlap_size\n",
    "    \n",
    "    imgs_per_width = math.ceil(float(img.width) / no_overlap_size)\n",
    "    imgs_per_height = math.ceil(float(img.height) / no_overlap_size)\n",
    "\n",
    "    padded_height = imgs_per_width * no_overlap_size + overlap_size\n",
    "    padded_width = imgs_per_width * no_overlap_size + overlap_size\n",
    "\n",
    "    padded_img = Image.new(\"RGB\", (padded_width, padded_height))\n",
    "    padded_img.paste(img)\n",
    "\n",
    "    patched_imgs, patched_annots = [], []\n",
    "\n",
    "    for row in range(imgs_per_height):\n",
    "        for col in range(imgs_per_width):\n",
    "            xmin, ymin = col * no_overlap_size, row * no_overlap_size\n",
    "            xmax, ymax = xmin + desired_image_size, ymin + desired_image_size\n",
    "\n",
    "            crop_box = (xmin, ymin, xmax, ymax)\n",
    "\n",
    "            cropped_img, cropped_annots = crop(padded_img, crop_box, annots, crop_tolerance)\n",
    "\n",
    "            if cropped_annots[\"category_id\"]:\n",
    "                patched_imgs.append(cropped_img)\n",
    "                patched_annots.append(cropped_annots)\n",
    "\n",
    "    return patched_imgs, patched_annots\n",
    "\n",
    "def patch_dataset(dataset_root: str,\n",
    "                  desired_image_size: int = 1024,\n",
    "                  overlap: float = 0.2,\n",
    "                  crop_tolerance: float=0.3):\n",
    "    \"\"\"Patches images in a dataset and saves the patched images and annotations.\n",
    "\n",
    "    Args:\n",
    "        dataset_root: The root directory of the dataset\n",
    "        desired_image_size: The desired size of each patch\n",
    "        overlap: The overlap between adjacent patches (as a fraction of `desired_image_size`)\n",
    "        crop_tolerance: The tolerance for considering an annotation as fully within a patch\n",
    "    \"\"\"\n",
    "    dataset_root = os.path.normpath(dataset_root)\n",
    "    annot_file = os.path.join(dataset_root, \"dataset.json\")\n",
    "    imgs_dir = os.path.join(dataset_root, \"imgs\")\n",
    "    dataset_parent = os.path.dirname(dataset_root)\n",
    "    patched_root = os.path.join(dataset_parent, os.path.basename(dataset_root) + \"_patched\")\n",
    "    os.makedirs(os.path.join(patched_root, \"imgs\"), exist_ok=True)\n",
    "    \n",
    "    patched_dataset = {\n",
    "        \"imgs\": [],\n",
    "        \"annotations\": []\n",
    "    }\n",
    "    \n",
    "    with open(annot_file, 'r') as annot_file:\n",
    "        dataset = json.load(annot_file)\n",
    "        \n",
    "    image_id = 1\n",
    "    for img_name, annotations in zip(dataset[\"imgs\"], dataset[\"annotations\"]):\n",
    "        img = Image.open(os.path.join(imgs_dir, f\"{img_name}.jpeg\"))\n",
    "        patched_imgs, patched_annots = patch_img(img, annotations,desired_image_size, overlap, crop_tolerance)\n",
    "        for img, annots in zip(patched_imgs, patched_annots):\n",
    "            patched_dataset[\"imgs\"].append(f\"{image_id}\")\n",
    "            patched_dataset[\"annotations\"].append(annots)\n",
    "            img.save(os.path.join(patched_root, \"imgs\", f\"{image_id}.jpeg\"), quality=100)\n",
    "            image_id += 1\n",
    "            \n",
    "    with open(os.path.join(patched_root, \"dataset.json\"), \"w\") as outfile: \n",
    "        json.dump(patched_dataset, outfile, indent=4)\n",
    "        \n",
    "patch_dataset(OUTPUT_DATASET, crop_tolerance=0) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
