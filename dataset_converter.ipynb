{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO - DESCRIBE THIS FILE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pillow\n",
    "\n",
    "from PIL import Image, ImageDraw \n",
    "from PIL.TiffTags import TAGS\n",
    "\n",
    "import os\n",
    "from typing import Any\n",
    "import json \n",
    "\n",
    "from typing import Any, NewType\n",
    "import os\n",
    "import csv\n",
    "import math\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "Box = NewType('Box', tuple[int,int,int,int])\n",
    "\n",
    "DATASET_SOURCE = \"F:\\\\dataUtils\\\\raw_data\" # FIXME change accordingly\n",
    "OUTPUT_DATASET = \"E:\\\\dataset\" # FIXME change accordingly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Math utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils\n",
    "def CXCYWHtoXYXY(box: Box) -> Box:\n",
    "    cx, cy, w, h = box\n",
    "    xmin = cx-w//2\n",
    "    ymin = cy-h//2\n",
    "    xmax = cx+(w+1)//2  # ceil\n",
    "    ymax = cy+(h+1)//2  # ceil\n",
    "    return xmin, ymin, xmax, ymax\n",
    "\n",
    "\n",
    "def get_res_metadata(img):\n",
    "        tiff_tags = {}\n",
    "        for tag, value in img.tag.items():\n",
    "            tag_name = TAGS.get(tag, tag)\n",
    "            tiff_tags[tag_name] = value\n",
    "        \n",
    "        res = {\n",
    "                \"xresolution\": tiff_tags['XResolution'][0][0]/tiff_tags['XResolution'][0][1],\n",
    "                \"yresolution\": tiff_tags['YResolution'][0][0]/tiff_tags['YResolution'][0][1],\n",
    "                \"resolutionUnit\": tiff_tags['ResolutionUnit'] \n",
    "        }\n",
    "        return res\n",
    "\n",
    "class ImageUtil:\n",
    "  \n",
    "    def __init__(self, img):\n",
    "        self.img = img\n",
    "        self.res = get_res_metadata(img)\n",
    "        self.xppu = float(self.res[\"xresolution\"])\n",
    "        self.yppu = float(self.res[\"yresolution\"])\n",
    "        \n",
    "    def areaU2P(self, area):\n",
    "        return float(area)*(max(self.xppu, self.yppu)**2)\n",
    "       \n",
    "    def areaP2U(self, area):\n",
    "        return float(area)/(max(self.xppu, self.yppu)**2)\n",
    "        \n",
    "\n",
    "class ImageUtilOpener:\n",
    "    def __init__(self, file_name):\n",
    "        self.file_name = file_name\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.img = Image.open(self.file_name)\n",
    "        return ImageUtil(self.img)\n",
    " \n",
    "    def __exit__(self, *args):\n",
    "        self.img.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read csv+tif ImageJ-created dataset, and convert to dict\n",
    "of images_path as keys and corresponding bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_annotations(name:str, annotation: dict[str, Any]) -> None:\n",
    "    \n",
    "    sanitized_annotations = {\n",
    "        \"category_id\": [],\n",
    "        \"boxes\": []\n",
    "    }\n",
    "    \n",
    "    bbox_dict: dict[Box, int] = dict()\n",
    "    for label, bbox in zip(annotation[\"category_id\"], annotation[\"boxes\"]):\n",
    "        if bbox in bbox_dict:\n",
    "            if bbox_dict[bbox] == label:\n",
    "                print(f\"WARNING: Duplicate bbox found in {name}: {bbox}\")\n",
    "            else:\n",
    "                print(f\"ERROR: Same bbox with different label found in {name}: {bbox}\")\n",
    "            continue\n",
    "        if min(bbox) < 0:\n",
    "            print(f\"Corrupted box found in {name}: {bbox}\")\n",
    "            continue\n",
    "\n",
    "        # TODO check if it's all conditions\n",
    "        bbox_dict[bbox] = label\n",
    "\n",
    "    for key in bbox_dict:\n",
    "        sanitized_annotations[\"category_id\"].append(bbox_dict[key])\n",
    "        sanitized_annotations[\"boxes\"].append(key)\n",
    "\n",
    "    return sanitized_annotations\n",
    "        \n",
    "def convert_annotations(csv_path: str, img_path: str) -> dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Converts csv, img pair to annotations list\n",
    "    \"\"\"\n",
    "    annotations: dict[str, Any] = {}\n",
    "    \n",
    "    name = os.path.basename(img_path).removesuffix(\".tif\")\n",
    "    \n",
    "    annotations = {\n",
    "        \"category_id\": [],\n",
    "        \"boxes\": []\n",
    "    }\n",
    "    \n",
    "    with ImageUtilOpener(img_path) as util:\n",
    "        if os.path.exists(csv_path): \n",
    "            with open(csv_path) as data_file:\n",
    "                data = csv.reader(data_file)\n",
    "                line_count = 0\n",
    "                try:\n",
    "                    for (num, label, area, category_id, category_name)  in data:\n",
    "                        if line_count != 0: #skip column titles\n",
    "                            split = label.split(':')\n",
    "                            (filename, (y, x)) = (split[0], split[-1].split('-'))\n",
    "                            areaInPixels = util.areaU2P(float(area))\n",
    "                            area2length = int(math.sqrt(areaInPixels / 3.14159) * 2) #assumes that nodule is a circle and calculates the width of square surrounding it\n",
    "                            annotations[\"category_id\"].append(int(category_id))\n",
    "                            bbox = CXCYWHtoXYXY((int(x), int(y), area2length,area2length))\n",
    "                            annotations[\"boxes\"].append(bbox)\n",
    "                        line_count+=1\n",
    "                except Exception as inst:\n",
    "                    annotations[\"boxes\"] = []\n",
    "                    annotations[\"category_id\"] = []\n",
    "                    print(type(inst))    \n",
    "                    print(inst) \n",
    "                    print(f\"{csv_path} Failed\")\n",
    "                     \n",
    "    return annotations\n",
    "    \n",
    "    \n",
    "def convert_dataset(data_path: str, imgs_path: str, res_path: str, replace_imgs=True):\n",
    "    img_list = [ \".\".join(f.split('.')[0:-1])  \n",
    "            for f in os.listdir(imgs_path) if os.path.isfile(imgs_path+'\\\\'+f) and f.endswith(\".tif\")\n",
    "            ] # creates list of imgs \n",
    "    \n",
    "    if replace_imgs:\n",
    "        try:\n",
    "            shutil.rmtree(res_path) #clears previos attempts\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    os.makedirs(f\"{res_path}\\\\imgs\\\\\", exist_ok=True)\n",
    "       \n",
    "    dataset = {\n",
    "        \"imgs\": [],\n",
    "        \"annotations\": []\n",
    "    }\n",
    "    id = 0\n",
    "    for name in img_list:\n",
    "        csv_path = f'{data_path}\\\\{name}.tif.csv'\n",
    "        img_path = f'{imgs_path}\\\\{name}.tif'\n",
    "        annotations = convert_annotations(csv_path, img_path)\n",
    "        if not annotations[\"boxes\"]:\n",
    "            continue # skip background\n",
    "        id+=1\n",
    "        if replace_imgs:\n",
    "            img = Image.open(img_path)\n",
    "            img.save(f\"{res_path}\\\\imgs\\\\{id}.jpeg\",quality=100)\n",
    "        \n",
    "        annotations = sanitize_annotations(name, annotations)\n",
    "        dataset[\"imgs\"].append(f\"{id}\")\n",
    "        dataset[\"annotations\"].append(annotations)\n",
    "    \n",
    "\n",
    "    with open(f\"{res_path}\\\\dataset.json\", \"w\") as outfile: \n",
    "        json.dump(dataset, outfile, indent=4)\n",
    "    print(\"finished converting\")\n",
    " \n",
    "convert_dataset(f\"{DATASET_SOURCE}\\\\csv\", f\"{DATASET_SOURCE}\\\\imgs\", OUTPUT_DATASET, replace_imgs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Patch dataset into images of desired size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def box_area(box: Box):\n",
    "    xmin, ymin, xmax, ymax = box\n",
    "    return max(0, xmax - xmin) * max(0, ymax - ymin)\n",
    "def intersection_area(box1: Box, box2: Box) -> int:\n",
    "    xmin1, ymin1, xmax1, ymax1 = box1\n",
    "    xmin2, ymin2, xmax2, ymax2 = box2\n",
    "    inter_xmin = max(xmin1, xmin2)\n",
    "    inter_ymin = max(ymin1, ymin2)\n",
    "    inter_xmax = min(xmax1, xmax2)\n",
    "    inter_ymax = min(ymax1, ymax2)\n",
    "    return box_area((inter_xmin, inter_ymin, inter_xmax, inter_ymax))\n",
    "\n",
    "def crop(img: Image.Image,\n",
    "         crop_box: Box,\n",
    "         annots: tuple[list[int], list[Box]],\n",
    "         crop_tolerance: float,\n",
    "         erase_not_tolerated: bool = True) -> tuple[Image.Image, tuple[list[int], list[Box]]]:\n",
    "    cropped_img = img.crop(crop_box)\n",
    "    cropped_annots = {\"category_id\": [], \"boxes\": []}\n",
    "    labels, bboxes = annots[\"category_id\"], annots[\"boxes\"]\n",
    "    \n",
    "    draw_context = ImageDraw.Draw(cropped_img)\n",
    "    for label, bbox in zip(labels, bboxes):\n",
    "        relative_bbox = (max(crop_box[0], bbox[0]) - crop_box[0],\n",
    "                         max(crop_box[1], bbox[1]) - crop_box[1],\n",
    "                         min(crop_box[2], bbox[2]) - crop_box[0],\n",
    "                         min(crop_box[3], bbox[3]) - crop_box[1])\n",
    "        intersection = float(intersection_area(bbox, crop_box)) / box_area(bbox)\n",
    "        if intersection > 1 - crop_tolerance:\n",
    "            cropped_annots[\"category_id\"].append(label)\n",
    "            cropped_annots[\"boxes\"].append(relative_bbox)\n",
    "        elif intersection > 0 and erase_not_tolerated:\n",
    "            draw_context.rectangle(relative_bbox, width=1, fill=\"purple\")\n",
    "\n",
    "    return cropped_img, cropped_annots\n",
    "\n",
    "def patch_img(img: Image.Image,\n",
    "          annots: dict[str, Any],\n",
    "          desired_image_size: int,\n",
    "          overlap: int,\n",
    "          crop_tolerance: float) -> tuple[list[Image.Image], list[tuple[list[int], list[Box]]]]:\n",
    "    imgs_per_width = math.ceil(float(img.width) / desired_image_size)\n",
    "    imgs_per_height = math.ceil(float(img.height) / desired_image_size)\n",
    "\n",
    "    padded_height = imgs_per_width * desired_image_size\n",
    "    padded_width = imgs_per_width * desired_image_size\n",
    "\n",
    "    padded_img = Image.new(\"RGB\", (padded_width, padded_height))\n",
    "    padded_img.paste(img)\n",
    "\n",
    "    patched_imgs, patched_annots = [], []\n",
    "\n",
    "    for row in range(imgs_per_height):\n",
    "        for col in range(imgs_per_width):\n",
    "            xmin, ymin = col * desired_image_size, row * desired_image_size\n",
    "            xmax, ymax = int(xmin + desired_image_size * (1 + overlap)), int(ymin + desired_image_size * (1 + overlap))\n",
    "            xmax, ymax = min(padded_width, xmax), min(padded_height, ymax)\n",
    "\n",
    "            crop_box = (xmin, ymin, xmax, ymax)\n",
    "\n",
    "            cropped_img, cropped_annots = crop(padded_img, crop_box, annots, crop_tolerance)\n",
    "\n",
    "            if cropped_annots[\"category_id\"]:\n",
    "                patched_imgs.append(cropped_img)\n",
    "                patched_annots.append(cropped_annots)\n",
    "            else:\n",
    "                print(f\"{row} {col} ignored\")\n",
    "\n",
    "    return patched_imgs, patched_annots\n",
    "\n",
    "def patch_dataset(dataset_root: str,\n",
    "                  desired_image_size: int = 1024,\n",
    "                  overlap: float = 0.2,\n",
    "                  crop_tolerance: float=0.3):\n",
    "    dataset_root = os.path.normpath(dataset_root)\n",
    "    annot_file = dataset_root + \"\\\\dataset.json\"\n",
    "    imgs_dir = dataset_root + \"\\\\imgs\"\n",
    "    dataset_parent = \"\\\\\".join(dataset_root.split('\\\\')[:-1])\n",
    "    patched_root = dataset_parent + '\\\\' + os.path.basename(dataset_root)+\"_patched\"\n",
    "    os.makedirs(f\"{patched_root}\\\\imgs\", exist_ok=True)\n",
    "    \n",
    "    patched_dataset = {\n",
    "        \"imgs\": [],\n",
    "        \"annotations\": []\n",
    "    }\n",
    "    \n",
    "    with open(annot_file, 'r') as annot_file:\n",
    "        dataset = json.load(annot_file)\n",
    "        \n",
    "    image_id = 1\n",
    "    for img_name, annotations in zip(dataset[\"imgs\"], dataset[\"annotations\"]):\n",
    "        img = Image.open(f\"{imgs_dir}\\\\{img_name}.jpeg\")\n",
    "        patched_imgs, patched_annots = patch_img(img, annotations,desired_image_size, overlap, crop_tolerance)\n",
    "        for img, annots in zip(patched_imgs, patched_annots):\n",
    "            patched_dataset[\"imgs\"].append(f\"{image_id}\")\n",
    "            patched_dataset[\"annotations\"].append(annots)\n",
    "            img.save(f\"{patched_root}\\\\imgs\\\\{image_id}.jpeg\", quality=100)\n",
    "            image_id+=1\n",
    "            \n",
    "    with open(f\"{patched_root}\\\\dataset.json\", \"w\") as outfile: \n",
    "        json.dump(patched_dataset, outfile, indent=4)\n",
    "        \n",
    "patch_dataset(OUTPUT_DATASET, crop_tolerance=0.9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
