{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "from finetuning.aleket_dataset import AleketDataset, download_dataset\n",
    "from finetuning.checkpoints import get_default_model, RunParams\n",
    "from finetuning.metrics import Evaluator\n",
    "from utils.analyze import count_analyze\n",
    "from utils.infer import infer\n",
    "from utils.visualize import visualize_bboxes, draw_heat_map\n",
    "from utils.predictor import Predictor\n",
    "from utils.consts import NUM_TO_CLASSES, VALIDATION_METRICS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_samples(dataset, images_to_visualize=4):\n",
    "    \"\"\"\n",
    "    Visualizes samples from the dataset with bounding boxes and labels.\n",
    "\n",
    "    Args:\n",
    "        dataset (AleketDataset): The dataset to visualize samples from.\n",
    "        images_to_visualize (int, optional): The number of images to visualize. Defaults to 4.\n",
    "    \"\"\"\n",
    "    visualized_images = []\n",
    "\n",
    "    for id, annot in enumerate(dataset.get_annots(None)):\n",
    "        if len(annot[\"boxes\"]) > 0:\n",
    "            img, target = dataset[id]\n",
    "            img = v2.functional.to_pil_image(img)\n",
    "\n",
    "            bboxes = target[\"boxes\"].cpu().tolist()\n",
    "            labels = [NUM_TO_CLASSES[label.item()] for label in target[\"labels\"]]\n",
    "\n",
    "            img_with_boxes = visualize_bboxes(img, bboxes, labels)\n",
    "            visualized_images.append(img_with_boxes)\n",
    "            if len(visualized_images) == images_to_visualize:\n",
    "                break\n",
    "\n",
    "    fig = plt.figure(figsize=(60, 20))\n",
    "    columns = 4\n",
    "    rows = 1\n",
    "    for i in range(1, columns * rows + 1):\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        plt.imshow(visualized_images[i - 1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "patched_dataset = AleketDataset(download_dataset(\"dataset_patched\", \"\"))\n",
    "full_dataset = AleketDataset(download_dataset(\"dataset_full_images\", \"\"))\n",
    "\n",
    "SAVE_DIR = \"eval\"\n",
    "os.makedirs(SAVE_DIR)\n",
    "\n",
    "params = RunParams()\n",
    "params.load(\"train_params.json\")\n",
    "\n",
    "model = get_default_model(device)\n",
    "model.load_state_dict(torch.load(\"model.pth\", weights_only=True))\n",
    "\n",
    "print(f\"Model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_indices = full_dataset.to_indices(params.validation_set.keys())\n",
    "val_subset = Subset(full_dataset, val_indices)\n",
    "image_list = [f\"{os.path.join(full_dataset.img_dir,name)}.jpeg\" for name in params.validation_set.keys()]\n",
    "\n",
    "with open(\"val_image_list.txt\", \"w\") as f:\n",
    "  for name in image_list:\n",
    "    f.write(name + \"\\n\") \n",
    "    \n",
    "parsed_params = params.parse(model, patched_dataset)\n",
    "train_dataloader = parsed_params[\"train_loader\"]\n",
    "val_dataloader = parsed_params[\"val_loader\"]\n",
    "augmentation = parsed_params[\"augmentation\"]\n",
    "\n",
    "count_analyze(full_dataset.get_annots(), save_folder=\"full_dataset_statistics\")\n",
    "count_analyze(patched_dataset.get_annots(train_dataloader.dataset.indices), save_folder=\"patched_dataset__train_statistics\")\n",
    "count_analyze(patched_dataset.get_annots(val_dataloader.dataset.indices), save_folder=\"patched_dataset_val_statistics\")\n",
    "\n",
    "patched_dataset.augmentation = augmentation\n",
    "visualize_samples(patched_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = Predictor(\n",
    "    model,\n",
    "    device,\n",
    "    detections_per_patch=150,\n",
    "    detections_per_image=500,\n",
    "    image_size_factor=1,\n",
    "    patches_per_batch=4,\n",
    ")\n",
    "\n",
    "iou_thrs = np.round(np.flip(np.arange(0.1, 0.5 + 1e-3, 0.1)), 2)\n",
    "score_thrs = np.round(np.arange(0.05, 0.95 + 1e-4, 0.1), 2)\n",
    "\n",
    "np.savetxt(os.path.join(SAVE_DIR, \"iou_thrs.csv\"), iou_thrs, delimiter=\",\", fmt=\"%.2f\")\n",
    "np.savetxt(\n",
    "    os.path.join(SAVE_DIR, \"score_thrs.csv\"), score_thrs, delimiter=\",\", fmt=\"%.2f\"\n",
    ")\n",
    "\n",
    "N = len(iou_thrs)\n",
    "S = len(score_thrs)\n",
    "\n",
    "eval = Evaluator(full_dataset.get_annots(val_indices))\n",
    "\n",
    "eval_res = {}\n",
    "results_ap = np.full((N, S), -1.0)\n",
    "results_aad = np.full((N, S), -1.0)\n",
    "results_acd = np.full((N, S), -1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, iou_thresh in enumerate(iou_thrs):\n",
    "    for j, score_thresh in tqdm(enumerate(score_thrs), total=S):\n",
    "        try:\n",
    "            preds = predictor.get_predictions(val_subset, iou_thresh, score_thresh)\n",
    "            stats = eval.eval(preds)\n",
    "            eval_res[(i, j)] = eval.eval_res\n",
    "            results_ap[i, j] = stats[VALIDATION_METRICS[0]]\n",
    "            results_acd[i, j] = stats[VALIDATION_METRICS[-2]]\n",
    "            results_aad[i, j] = stats[VALIDATION_METRICS[-1]]\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\n",
    "    os.path.join(SAVE_DIR, \"ap_analysis.csv\"), results_ap, delimiter=\",\", fmt=\"%.4f\"\n",
    ")\n",
    "np.savetxt(\n",
    "    os.path.join(SAVE_DIR, \"aad_analysis.csv\"), results_aad, delimiter=\",\", fmt=\"%.4f\"\n",
    ")\n",
    "np.savetxt(\n",
    "    os.path.join(SAVE_DIR, \"acd_analysis.csv\"), results_acd, delimiter=\",\", fmt=\"%.4f\"\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(60, 10))\n",
    "\n",
    "draw_heat_map(\"AP\", \"Score thresholds\", \"IoU thresholds\", results_ap, axes[0], score_thrs, iou_thrs)\n",
    "draw_heat_map(\"AAD\", \"Score thresholds\", \"IoU thresholds\", results_aad, axes[1], score_thrs, iou_thrs)\n",
    "draw_heat_map(\"ACD\", \"Score thresholds\", \"IoU thresholds\", results_acd, axes[2], score_thrs, iou_thrs)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_IOU_THRESH = 0.2\n",
    "BEST_SCORE_THRESH = 0.8\n",
    "\n",
    "preds = predictor.get_predictions(val_subset, BEST_IOU_THRESH, BEST_SCORE_THRESH)\n",
    "stats = eval.eval(preds)\n",
    "\n",
    "print(\"ALL CLASSES METRICS:\")\n",
    "for metric_name, metric_value in stats.items():\n",
    "    print(f\"\\tValidation {metric_name}: {metric_value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer(\n",
    "    predictor,\n",
    "    image_list,\n",
    "    NUM_TO_CLASSES,\n",
    "    os.path.join(SAVE_DIR, \"infer\"),\n",
    "    iou_thresh=BEST_IOU_THRESH,\n",
    "    score_thresh=BEST_SCORE_THRESH,\n",
    "    num_of_annotations_to_save=-1,\n",
    "    save_annotated_images=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".wslvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
