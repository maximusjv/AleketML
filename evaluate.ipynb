{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "from data.aleket_dataset import AleketDataset, download_dataset\n",
    "from data.checkpoints import get_default_model, RunParams\n",
    "from metrics.metrics import Evaluator\n",
    "from inference.infer import infer\n",
    "from utils.visualize import visualize_bboxes, draw_heat_map\n",
    "from inference.predictor import Predictor, postprocess\n",
    "from inference.models import FasterRCNN_ResNet50_FPN_v2\n",
    "from config.consts import NUM_TO_CLASSES, VALIDATION_METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_samples(dataset: AleketDataset, images_to_visualize=4):\n",
    "    \"\"\"\n",
    "    Visualizes samples from the dataset with bounding boxes and labels.\n",
    "\n",
    "    Args:\n",
    "        dataset (AleketDataset): The dataset to visualize samples from.\n",
    "        images_to_visualize (int, optional): The number of images to visualize. Defaults to 4.\n",
    "    \"\"\"\n",
    "    visualized_images = []\n",
    "\n",
    "    for id, annot in enumerate(dataset.get_annots(None)):\n",
    "        if len(annot[\"boxes\"]) > 0:\n",
    "            img, target = dataset[id]\n",
    "            img = v2.functional.to_pil_image(img)\n",
    "\n",
    "            bboxes = target[\"boxes\"].cpu().tolist()\n",
    "            labels = [NUM_TO_CLASSES[label] for label in target[\"labels\"].cpu().tolist()]\n",
    "\n",
    "            img_with_boxes = visualize_bboxes(img, bboxes, labels)\n",
    "            visualized_images.append(img_with_boxes)\n",
    "            if len(visualized_images) == images_to_visualize:\n",
    "                break\n",
    "\n",
    "    fig = plt.figure(figsize=(60, 20))\n",
    "    columns = 4\n",
    "    rows = 1\n",
    "    for i in range(1, columns * rows + 1):\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        plt.imshow(visualized_images[i - 1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "full_dataset = AleketDataset(download_dataset(\"../datasets/orobanche_cummana/images\", \"\"))\n",
    "patched_dataset = AleketDataset(download_dataset(\"../datasets/orobanche_cummana/patched/images\", \"\"))\n",
    "\n",
    "params = RunParams()\n",
    "params.load(\"train_params.json\")\n",
    "\n",
    "model = FasterRCNN_ResNet50_FPN_v2(\"models/model.pth\")\n",
    "\n",
    "print(f\"Model loaded\")\n",
    "\n",
    "SAVE_DIR = \"eval\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'FasterRCNN_ResNet50_FPN_v2' object has no attribute 'parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m image_list:\n\u001b[0;32m      8\u001b[0m         f\u001b[38;5;241m.\u001b[39mwrite(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mnormpath(name) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m parsed_params \u001b[38;5;241m=\u001b[39m \u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatched_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m parsed_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_loader\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     12\u001b[0m val_dataloader \u001b[38;5;241m=\u001b[39m parsed_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loader\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\maksi\\Documents\\AleketML\\data\\checkpoints.py:182\u001b[0m, in \u001b[0;36mRunParams.parse\u001b[1;34m(self, model, dataset)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;124;03mParses training parameters and sets up training components.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;124;03m    dict: A dictionary containing training components.\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    178\u001b[0m train_dataloader, val_dataloader \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mcreate_dataloaders(\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_indices, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_indices, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader_workers\n\u001b[0;32m    180\u001b[0m )\n\u001b[1;32m--> 182\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mdefault_optimizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    183\u001b[0m lr_scheduler \u001b[38;5;241m=\u001b[39m default_lr_scheduler(optimizer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_scheduler)\n\u001b[0;32m    184\u001b[0m run_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_name)\n",
      "File \u001b[1;32mc:\\Users\\maksi\\Documents\\AleketML\\data\\checkpoints.py:45\u001b[0m, in \u001b[0;36mdefault_optimizer\u001b[1;34m(model, params)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_optimizer\u001b[39m(model, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     35\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124;03m    Creates a default SGD optimizer for the model.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;124;03m        SGD: The SGD optimizer.\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m     model_params \u001b[38;5;241m=\u001b[39m [p \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m() \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mrequires_grad]\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m params:\n\u001b[0;32m     47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m SGD(params\u001b[38;5;241m=\u001b[39mmodel_params, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'FasterRCNN_ResNet50_FPN_v2' object has no attribute 'parameters'"
     ]
    }
   ],
   "source": [
    "val_indices = full_dataset.load_split_indices(\"../datasets/orobanche_cummana/autosplit_val.txt\")\n",
    "val_subset = Subset(full_dataset, val_indices)\n",
    "\n",
    "image_list = [full_dataset.image_files[ind] for ind in val_indices]\n",
    "\n",
    "with open(\"val_image_list.txt\", \"w\") as f:\n",
    "    for name in image_list:\n",
    "        f.write(os.path.normpath(name) + \"\\n\")\n",
    "\n",
    "parsed_params = params.parse(model, patched_dataset)\n",
    "train_dataloader = parsed_params[\"train_loader\"]\n",
    "val_dataloader = parsed_params[\"val_loader\"]\n",
    "augmentation = parsed_params[\"augmentation\"]\n",
    "\n",
    "\n",
    "patched_dataset.augmentation = augmentation\n",
    "visualize_samples(patched_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = Predictor(\n",
    "    model,\n",
    "    device,\n",
    "    detections_per_patch=300,\n",
    "    pre_wbf_detections=2500,\n",
    "    image_size_factor=1,\n",
    "    patches_per_batch=8,\n",
    ")\n",
    "\n",
    "eval = Evaluator(full_dataset.get_annots(val_indices), use_categories=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predictor.get_predictions(\n",
    "    val_subset, 1, 0.05\n",
    ")  # disable wbf postprocess (using small scorethreshold to increase performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_thrs = np.round(np.flip(np.arange(0.1, 0.7 + 1e-3, 0.05)), 2)\n",
    "score_thrs = np.round(np.arange(0.05, 0.95 + 1e-4, 0.05), 2)\n",
    "\n",
    "np.savetxt(os.path.join(SAVE_DIR, \"iou_thrs.csv\"), iou_thrs, delimiter=\",\", fmt=\"%.2f\")\n",
    "np.savetxt(\n",
    "    os.path.join(SAVE_DIR, \"score_thrs.csv\"), score_thrs, delimiter=\",\", fmt=\"%.2f\"\n",
    ")\n",
    "\n",
    "N = len(iou_thrs)\n",
    "S = len(score_thrs)\n",
    "\n",
    "eval_res = {}\n",
    "results_ap = np.full((N, S), -1.0)\n",
    "results_p = np.full((N, S), -1.0)\n",
    "results_r = np.full((N, S), -1.0)\n",
    "results_aad = np.full((N, S), -1.0)\n",
    "results_acd = np.full((N, S), -1.0)\n",
    "\n",
    "print(\"start analyzing...\")\n",
    "for i, iou_thresh in enumerate(iou_thrs):\n",
    "    for j, score_thresh in tqdm(enumerate(score_thrs), total=S):\n",
    "        try:\n",
    "            postproccessed = {}\n",
    "            for pi, p in preds.items():\n",
    "                to_process = {\n",
    "                    \"boxes\": np.copy(p[\"boxes\"]),\n",
    "                    \"scores\": np.copy(p[\"scores\"]),\n",
    "                    \"labels\": np.copy(p[\"labels\"])\n",
    "                }\n",
    "                postproccessed[pi] = postprocess(to_process,predictor.pre_wbf_detections, score_thresh, iou_thresh)\n",
    "            stats = eval.eval(postproccessed)\n",
    "            eval_res[(i, j)] = eval.eval_res\n",
    "            results_ap[i, j] = stats[VALIDATION_METRICS[0]]\n",
    "            results_acd[i, j] = stats[VALIDATION_METRICS[-2]]\n",
    "            results_aad[i, j] = stats[VALIDATION_METRICS[-1]]\n",
    "            results_p[i, j] = stats[VALIDATION_METRICS[2]]\n",
    "            results_r[i, j] = stats[VALIDATION_METRICS[1]]\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\n",
    "    os.path.join(SAVE_DIR, \"ap_analysis.csv\"), results_ap, delimiter=\",\", fmt=\"%.4f\"\n",
    ")\n",
    "np.savetxt(\n",
    "    os.path.join(SAVE_DIR, \"aad_analysis.csv\"), results_aad, delimiter=\",\", fmt=\"%.4f\"\n",
    ")\n",
    "np.savetxt(\n",
    "    os.path.join(SAVE_DIR, \"acd_analysis.csv\"), results_acd, delimiter=\",\", fmt=\"%.4f\"\n",
    ")\n",
    "np.savetxt(\n",
    "    os.path.join(SAVE_DIR, \"r_analysis.csv\"), results_r, delimiter=\",\", fmt=\"%.4f\"\n",
    ")\n",
    "np.savetxt(\n",
    "    os.path.join(SAVE_DIR, \"p_analysis.csv\"), results_p, delimiter=\",\", fmt=\"%.4f\"\n",
    ")\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(5, 1, figsize=(160, 30))\n",
    "\n",
    "draw_heat_map(\n",
    "    \"AP\",\n",
    "    \"Score thresholds\",\n",
    "    \"IoU thresholds\",\n",
    "    results_ap,\n",
    "    axes[0],\n",
    "    score_thrs,\n",
    "    iou_thrs,\n",
    ")\n",
    "draw_heat_map(\n",
    "    \"PRECISION\",\n",
    "    \"Score thresholds\",\n",
    "    \"IoU thresholds\",\n",
    "    results_p,\n",
    "    axes[1],\n",
    "    score_thrs,\n",
    "    iou_thrs,\n",
    ")\n",
    "draw_heat_map(\n",
    "    \"RECALL\",\n",
    "    \"Score thresholds\",\n",
    "    \"IoU thresholds\",\n",
    "    results_r,\n",
    "    axes[2],\n",
    "    score_thrs,\n",
    "    iou_thrs,\n",
    ")\n",
    "draw_heat_map(\n",
    "    \"AAD\",\n",
    "    \"Score thresholds\",\n",
    "    \"IoU thresholds\",\n",
    "    results_aad,\n",
    "    axes[3],\n",
    "    score_thrs,\n",
    "    iou_thrs,\n",
    ")\n",
    "draw_heat_map(\n",
    "    \"ACD\",\n",
    "    \"Score thresholds\",\n",
    "    \"IoU thresholds\",\n",
    "    results_acd,\n",
    "    axes[4],\n",
    "    score_thrs,\n",
    "    iou_thrs,\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_IOU_THRESH = 0.25\n",
    "BEST_SCORE_THRESH = 0.75\n",
    "\n",
    "preds = predictor.get_predictions(val_subset, BEST_IOU_THRESH, BEST_SCORE_THRESH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval = Evaluator(full_dataset.get_annots(val_indices), use_categories=False)\n",
    "stats = eval.eval(preds)\n",
    "\n",
    "print(\"ALL CLASSES METRICS:\")\n",
    "for metric_name, metric_value in stats.items():\n",
    "    print(f\"\\tValidation {metric_name}: {metric_value:.3f}\")\n",
    "\n",
    "np.savetxt(os.path.join(SAVE_DIR, \"pr_recalls.csv\"), eval.recall_thrs, fmt=\"%.4f\")\n",
    "np.savetxt(\n",
    "    os.path.join(SAVE_DIR, \"pr_curve.csv\"), eval.eval_res[\"pr_curve\"], fmt=\"%.4f\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer(\n",
    "    predictor,\n",
    "    image_list,\n",
    "    NUM_TO_CLASSES,\n",
    "    os.path.join(SAVE_DIR, \"infer\"),\n",
    "    iou_thresh=BEST_IOU_THRESH,\n",
    "    score_thresh=BEST_SCORE_THRESH,\n",
    "    save_annots=True,\n",
    "    save_images=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
